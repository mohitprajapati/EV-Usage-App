{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LMVXI0giegud"
   },
   "outputs": [],
   "source": [
    "import numpy as np # Importing numpy for performing array and matrix operations \n",
    "import pandas as pd # Importing pandas to read data in dataframe\n",
    "\n",
    "# Libraries to plot the distribution of classes \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime #I will use this to Convert ISO8601 format to unix time\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import time #I will use this to Convert ISO8601 format to unix time\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn import linear_model  #Importing linear models like logistics regression and SVC\n",
    "from sklearn.preprocessing import LabelEncoder  # To convert every class  into numeric labels \n",
    "from sklearn.metrics import f1_score       # to calculate F1 score \n",
    "from sklearn.metrics import classification_report # to know every metric\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from collections import deque\n",
    "from tensorflow.keras.layers import Layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Input,concatenate\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, Model, backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uju_Ey-dSzVv",
    "outputId": "f06ab3ca-89ba-4da4-d52e-b2bb57e81c8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 30 05:59:24 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   41C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40OkYNogcDP0",
    "outputId": "16d126d2-f06e-468b-bbfc-c4bab4224901"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sFOd2xhcetcz"
   },
   "outputs": [],
   "source": [
    "data1= pd.read_csv('/content/drive/MyDrive/AAIC_Assignment/ytrain_NpxebDC.csv', parse_dates=['timestamp'],\n",
    "index_col= ['timestamp']) # Reading the csv file in data dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pdrnKXJhevWs",
    "outputId": "22c20d77-dc90-4f4c-8262-ac39778a6f1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in data1:    # for every column in the data frame\n",
    "    if col!='timestamp':\n",
    "        data1[col]=data1[col].fillna('Offline')  # Filling the missing class label with Down as explained above\n",
    "data1['S7-T1'].isnull().sum() # counting the NAN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9fFccNxnHMw"
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution(\n",
    "    config=None, device_policy=None, execution_mode=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pyX3IsuXexgA"
   },
   "outputs": [],
   "source": [
    "data, test_data=train_test_split(data1, test_size=0.10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CpIj0Izez4u"
   },
   "outputs": [],
   "source": [
    "def date_time(data):\n",
    "# Initializing Empty lists\n",
    "   \n",
    "    month=[]\n",
    "    week=[]\n",
    "    date=[]\n",
    "    hr=[]\n",
    "    minute=[]\n",
    "\n",
    "# I have made timestamp column as an index of the dataframe for easy plotting operations\n",
    "    for i in data.index: # For every index of the dataframe\n",
    "    #print(i)\n",
    "    #break\n",
    "    #dt = datetime.datetime.strptime(i, \"%Y-%m-%dT%H:%M:%S%z\")\n",
    "        dt=i\n",
    "    # Appending the month, day, weekday, hour and minute in lists\n",
    "        \n",
    "        month.append(dt.month)\n",
    "        week.append(dt.weekday()) #Monday is 0 and Sunday is 6\n",
    "        date.append(dt.day)\n",
    "        hr.append(dt.hour)\n",
    "        minute.append(dt.minute)\n",
    "# making X as a data frame \n",
    "    return pd.DataFrame(list(zip( month, week, date, hr, minute)), columns =['Month_name', 'Week_number', 'Date', 'Hour', 'Minute'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z8aHbnPGgk7J",
    "outputId": "8a00a35b-3d1c-4a62-bc47-4c481deb4a09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "X=date_time(data)\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "3yV6AoWHgmtx",
    "outputId": "237e708e-da4e-4f38-a2d6-8decb7fbeba3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month_name</th>\n",
       "      <th>Week_number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month_name  Week_number  Date  Hour  Minute\n",
       "0          10            4     2     4      45\n",
       "1          10            4     2     5       0\n",
       "2          10            4     2     5      15\n",
       "3          10            4     2     5      30\n",
       "4          10            4     2     5      45"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=date_time(test_data)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Nsp23DWe3U4"
   },
   "outputs": [],
   "source": [
    "### DEFINE T2V LAYER ###\n",
    "#https://towardsdatascience.com/time2vec-for-time-series-features-encoding-a03a4f3f937e\n",
    "class T2V(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, output_dim=None):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        \n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.W = self.add_weight(name='W',shape=(input_shape[-1], self.output_dim), initializer='uniform',trainable=True)\n",
    "\n",
    "        self.P = self.add_weight(name='P',shape=(input_shape[1], self.output_dim), initializer='uniform',trainable=True)\n",
    "\n",
    "        self.w = self.add_weight(name='w', shape=(input_shape[1], 1),initializer='uniform', trainable=True)\n",
    "\n",
    "        self.p = self.add_weight(name='p',shape=(input_shape[1], 1),initializer='uniform', trainable=True)\n",
    "\n",
    "        #super(T2V, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        \n",
    "        original = tf.multiply(self.w, x)\n",
    "        original=tf.add(original, self.p)\n",
    "        \n",
    "        sin_trans = tf.sin(K.dot(x, self.W) + self.P)\n",
    "        \n",
    "        return tf.concat([sin_trans, original], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HxN6P6bWe5k9"
   },
   "outputs": [],
   "source": [
    "def label_encoder(column):\n",
    "    '''\n",
    "    This function help us to Encode the class labels of \n",
    "    the corresponding terminal into their respective \n",
    "    numeric labels\n",
    "    '''\n",
    "    if column =='Available': # Available ==0\n",
    "        return 0\n",
    "    elif column=='Charging': # charging==1\n",
    "        return 1\n",
    "    elif column=='Passive': # Passive==2\n",
    "        return 2\n",
    "    elif column=='Offline': # offline==3\n",
    "        return 3\n",
    "    else: return 4    # Down==4\n",
    "# utilize it along with apply method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8EserGAWe8aU"
   },
   "outputs": [],
   "source": [
    "### DEFINE MODEL STRUCTURES ###\n",
    "\n",
    "def T2V_NN(t2v_dim, dim):\n",
    "\n",
    "    inp = layers.Input(shape=(dim,1))\n",
    "    x = T2V(t2v_dim)(inp)\n",
    "    x = layers.LSTM(5, activation='tanh', return_sequences=True)(x)\n",
    "    \n",
    "    x = layers.LSTM(5, activation='tanh')(x)\n",
    "    #x= layers.Dense(1, activation='relu')(x)\n",
    "    #x=layers.BatchNormalization()(x)\n",
    "    #x=layers.Dense(64, activation='relu')(x)\n",
    "    #x=layers.Dropout(0.2)(x)\n",
    "    #x=layers.BatchNormalization()(x)\n",
    "    #x=layers.Dense(10)(x)\n",
    "    x = layers.Dense(5,activation='softmax')(x)\n",
    "    \n",
    "\n",
    "    m = Model(inp, x)\n",
    "\n",
    "    return m\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NDdcNPNYfuop",
    "outputId": "62851c6c-12de-4cb6-e45e-8db0a7590ea1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20769\n",
       "2     2567\n",
       "1     2470\n",
       "3     2286\n",
       "4       16\n",
       "Name: S11-T1, dtype: int64"
      ]
     },
     "execution_count": 274,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terminal= data.columns[17]\n",
    "weekend=data[terminal].apply(label_encoder)\n",
    "num_class=weekend.unique()\n",
    "num_class.sort()\n",
    "weekend_test=test_data[terminal].apply(label_encoder)\n",
    "\n",
    "y=np.array(weekend).reshape(-1,1) # label encoding class labels\n",
    "y_test=np.array(weekend_test).reshape(-1,1)\n",
    "y_train1 = to_categorical(y, 5)\n",
    "y_test1 = to_categorical(y_test, 5)\n",
    "weekend.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d_ryYaFCZA-J",
    "outputId": "520db299-744e-4311-b363-80a5902868e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2616\n",
       "1     327\n",
       "2     135\n",
       "3      46\n",
       "Name: S11-T1, dtype: int64"
      ]
     },
     "execution_count": 275,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekend_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cZ0yMhyNfat1",
    "outputId": "0c82d49f-4bc7-453b-9aa3-109d3ddb2402"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "563/563 [==============================] - 7s 7ms/step - loss: 1.0203 - accuracy: 0.7218\n",
      "Epoch 2/200\n",
      "563/563 [==============================] - 4s 6ms/step - loss: 0.8997 - accuracy: 0.7389\n",
      "Epoch 3/200\n",
      "563/563 [==============================] - 4s 6ms/step - loss: 0.8835 - accuracy: 0.7389\n",
      "Epoch 4/200\n",
      "563/563 [==============================] - 4s 6ms/step - loss: 0.8791 - accuracy: 0.7389\n",
      "Epoch 5/200\n",
      "563/563 [==============================] - 4s 6ms/step - loss: 0.8781 - accuracy: 0.7389\n",
      "Epoch 6/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8776 - accuracy: 0.7389\n",
      "Epoch 7/200\n",
      "563/563 [==============================] - 4s 6ms/step - loss: 0.8773 - accuracy: 0.7389\n",
      "Epoch 8/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8772 - accuracy: 0.7389\n",
      "Epoch 9/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8770 - accuracy: 0.7389\n",
      "Epoch 10/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8768 - accuracy: 0.7389\n",
      "Epoch 11/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8766 - accuracy: 0.7389\n",
      "Epoch 12/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8763 - accuracy: 0.7389\n",
      "Epoch 13/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8761 - accuracy: 0.7389\n",
      "Epoch 14/200\n",
      "563/563 [==============================] - 4s 6ms/step - loss: 0.8758 - accuracy: 0.7389\n",
      "Epoch 15/200\n",
      "563/563 [==============================] - 4s 6ms/step - loss: 0.8748 - accuracy: 0.7389\n",
      "Epoch 16/200\n",
      "563/563 [==============================] - 4s 6ms/step - loss: 0.8724 - accuracy: 0.7389\n",
      "Epoch 17/200\n",
      "563/563 [==============================] - 4s 6ms/step - loss: 0.8678 - accuracy: 0.7389\n",
      "Epoch 18/200\n",
      "563/563 [==============================] - 4s 6ms/step - loss: 0.8641 - accuracy: 0.7389\n",
      "Epoch 19/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8597 - accuracy: 0.7389\n",
      "Epoch 20/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8548 - accuracy: 0.7389\n",
      "Epoch 21/200\n",
      "563/563 [==============================] - 4s 6ms/step - loss: 0.8511 - accuracy: 0.7389\n",
      "Epoch 22/200\n",
      "563/563 [==============================] - 4s 6ms/step - loss: 0.8458 - accuracy: 0.7389\n",
      "Epoch 23/200\n",
      "563/563 [==============================] - 4s 6ms/step - loss: 0.8411 - accuracy: 0.7389\n",
      "Epoch 24/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8384 - accuracy: 0.7389\n",
      "Epoch 25/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8359 - accuracy: 0.7389\n",
      "Epoch 26/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8334 - accuracy: 0.7389\n",
      "Epoch 27/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8319 - accuracy: 0.7389\n",
      "Epoch 28/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8290 - accuracy: 0.7389\n",
      "Epoch 29/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8281 - accuracy: 0.7389\n",
      "Epoch 30/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8250 - accuracy: 0.7389\n",
      "Epoch 31/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8227 - accuracy: 0.7389\n",
      "Epoch 32/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8199 - accuracy: 0.7389\n",
      "Epoch 33/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8233 - accuracy: 0.7389\n",
      "Epoch 34/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8163 - accuracy: 0.7389\n",
      "Epoch 35/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8101 - accuracy: 0.7389\n",
      "Epoch 36/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8060 - accuracy: 0.7389\n",
      "Epoch 37/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8010 - accuracy: 0.7389\n",
      "Epoch 38/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.7967 - accuracy: 0.7389\n",
      "Epoch 39/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.7957 - accuracy: 0.7389\n",
      "Epoch 40/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.7981 - accuracy: 0.7389\n",
      "Epoch 41/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.7870 - accuracy: 0.7389\n",
      "Epoch 42/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.7896 - accuracy: 0.7401\n",
      "Epoch 43/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8012 - accuracy: 0.7388\n",
      "Epoch 44/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.7757 - accuracy: 0.7399\n",
      "Epoch 45/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.7924 - accuracy: 0.7390\n",
      "Epoch 46/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.7662 - accuracy: 0.7417\n",
      "Epoch 47/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.8148 - accuracy: 0.7342\n",
      "Epoch 48/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.7922 - accuracy: 0.7354\n",
      "Epoch 49/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.7798 - accuracy: 0.7384\n",
      "Epoch 50/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.7563 - accuracy: 0.7389\n",
      "Epoch 51/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.7452 - accuracy: 0.7394\n",
      "Epoch 52/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.7367 - accuracy: 0.7543\n",
      "Epoch 53/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.7331 - accuracy: 0.7595\n",
      "Epoch 54/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.7384 - accuracy: 0.7604\n",
      "Epoch 55/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.7531 - accuracy: 0.7583\n",
      "Epoch 56/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.7185 - accuracy: 0.7773\n",
      "Epoch 57/200\n",
      "563/563 [==============================] - 4s 6ms/step - loss: 0.7025 - accuracy: 0.7839\n",
      "Epoch 58/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6949 - accuracy: 0.7892\n",
      "Epoch 59/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6998 - accuracy: 0.7870\n",
      "Epoch 60/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6888 - accuracy: 0.7878\n",
      "Epoch 61/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6768 - accuracy: 0.7951\n",
      "Epoch 62/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6708 - accuracy: 0.7977\n",
      "Epoch 63/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6623 - accuracy: 0.8007\n",
      "Epoch 64/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6545 - accuracy: 0.8046\n",
      "Epoch 65/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6519 - accuracy: 0.8070\n",
      "Epoch 66/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6432 - accuracy: 0.8078\n",
      "Epoch 67/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6416 - accuracy: 0.8076\n",
      "Epoch 68/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6398 - accuracy: 0.8088\n",
      "Epoch 69/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6402 - accuracy: 0.8033\n",
      "Epoch 70/200\n",
      "563/563 [==============================] - 4s 6ms/step - loss: 0.6330 - accuracy: 0.8053\n",
      "Epoch 71/200\n",
      "563/563 [==============================] - 4s 6ms/step - loss: 0.6249 - accuracy: 0.8095\n",
      "Epoch 72/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6319 - accuracy: 0.8079\n",
      "Epoch 73/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6193 - accuracy: 0.8097\n",
      "Epoch 74/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6269 - accuracy: 0.8100\n",
      "Epoch 75/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6214 - accuracy: 0.8076\n",
      "Epoch 76/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6284 - accuracy: 0.8081\n",
      "Epoch 77/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6336 - accuracy: 0.8087\n",
      "Epoch 78/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6118 - accuracy: 0.8101\n",
      "Epoch 79/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6257 - accuracy: 0.8043\n",
      "Epoch 81/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6128 - accuracy: 0.8088\n",
      "Epoch 82/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6346 - accuracy: 0.8060\n",
      "Epoch 83/200\n",
      "563/563 [==============================] - 4s 7ms/step - loss: 0.6150 - accuracy: 0.8075\n",
      "Epoch 00083: early stopping\n"
     ]
    }
   ],
   "source": [
    "  tf.keras.backend.clear_session()\n",
    "\n",
    "model = T2V_NN(16, 5)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', mode='auto', verbose=2,patience=5)\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=tf.keras.optimizers.Adam())\n",
    "\n",
    "    \n",
    "    #class_weights = class_weight.compute_class_weight('balanced',weekend.unique(y) ,data[terminal])\n",
    "    #class_weights = dict(enumerate(class_weights))\n",
    "model.fit(X, y_train1, epochs=200, batch_size=50, verbose=1, shuffle =False, callbacks=[callback])\n",
    "        \n",
    "y_pred=model.predict(X)\n",
    "val_predict=np.argmax(y_pred, axis=1) \n",
    "val_target=np.argmax(y_train1, axis=1) \n",
    "state_f1=f1_score(val_target, val_predict, average=None)\n",
    "        \n",
    "y_pred_test=model.predict(X_test)\n",
    "val_predict=np.argmax(y_pred_test, axis=1) \n",
    "val_target=np.argmax(y_test1, axis=1) \n",
    "state_f1_test=f1_score(val_target, val_predict, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wXzBh6F-gUz2",
    "outputId": "fe301af5-9261-4584-da73-640bd3c1eb37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88374691 0.         0.43485915 0.72756156 0.        ]\n",
      "[0.59222333 0.         0.         0.03494927]\n"
     ]
    }
   ],
   "source": [
    "print(state_f1)\n",
    "print(state_f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vBR26D5uQ4U5",
    "outputId": "50f8cfd2-025e-40af-c15b-d35aade9b1d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28108\n"
     ]
    }
   ],
   "source": [
    "av_count=0\n",
    "ch_count=0\n",
    "pa_count=0\n",
    "do_count=0                             \n",
    "of_count=0\n",
    "\n",
    "    \n",
    "terminal= data.columns[17] # Extracting the column names from the dataframe\n",
    "labels=data[terminal]\n",
    "for i in labels:\n",
    "        #print(i)\n",
    "    if i=='Available':\n",
    "        av_count+=1\n",
    "    if i=='Charging':\n",
    "        ch_count+=1\n",
    "    if i=='Passive':\n",
    "        pa_count+=1\n",
    "    if i=='Down':\n",
    "        do_count+=1\n",
    "    if i=='Offline':\n",
    "        of_count+=1\n",
    "tot_count=av_count+ch_count+pa_count+do_count+of_count\n",
    "print(tot_count)\n",
    "prob_list=[0,0,0,0,0]# order available, passive, charging, offline, down\n",
    "prob_list[0]=av_count/tot_count\n",
    "prob_list[1]=pa_count/tot_count\n",
    "prob_list[2]=ch_count/tot_count\n",
    "prob_list[3]=of_count/tot_count\n",
    "prob_list[4]=do_count/tot_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KeKmu_IzRPMC",
    "outputId": "4d02945b-60ef-4c29-a9b1-23c210c36be6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Combined Average F1 scores of train Terminals  [0.88374691 0.         0.43485915 0.72756156 0.        ]\n",
      "The Combined Average F1 scores of test Terminals  [0.59222333 0.         0.         0.03494927]\n",
      "The final F1 test score is 0.7503859199634487\n",
      "The final F1 test score is 0.44043618776788723\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"The Combined Average F1 scores of train Terminals \",state_f1) # order available, passive, charging, offline, down\n",
    "\n",
    "\n",
    "print(\"The Combined Average F1 scores of test Terminals \",state_f1_test) # order available, passive, charging, offline,down\n",
    "\n",
    "f1_final=0\n",
    "#print(\" The probabilities of the train states\",prob_list)\n",
    "for i in range(len(prob_list)):\n",
    "    f1_final+=prob_list[i]*state_f1[i]\n",
    "print('The final F1 test score is', f1_final)\n",
    "\n",
    "f1_final_test=0\n",
    "while(len(state_f1_test)!=6):\n",
    "  state_f1_test=  np.append(state_f1_test, 0)\n",
    "\n",
    "for i in range(len(prob_list)):\n",
    "    \n",
    "    f1_final_test+=prob_list[i]*state_f1_test[i]\n",
    "print('The final F1 test score is', f1_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bLdLzbLjfLZb",
    "outputId": "0e808706-c46c-4282-d5b7-aae4d3ca5607"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 2/20 [00:48<07:20, 24.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4/20 [01:14<05:34, 20.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00114: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 6/20 [07:02<15:36, 66.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00148: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 7/20 [14:32<39:22, 181.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00170: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 8/20 [24:01<59:35, 297.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00013: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 11/20 [24:49<32:00, 213.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00149: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 12/20 [32:18<37:52, 284.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00133: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 13/20 [39:47<38:54, 333.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00028: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 14/20 [42:16<27:49, 278.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 15/20 [42:45<16:56, 203.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00071: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 16/20 [46:22<13:50, 207.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00100: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 17/20 [51:52<12:12, 244.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00039: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 18/20 [53:55<06:55, 207.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00182: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 19/20 [1:03:24<05:16, 316.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00076: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [1:07:15<00:00, 201.80s/it]\n"
     ]
    }
   ],
   "source": [
    "tf.executing_eagerly()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "f1_state_terminal=[0,0,0,0,0, 0] # order available, passive, charging, offline, down\n",
    "f1_state_terminal_test=[0,0,0,0,0, 0] # order available, passive, charging, offline, down\n",
    "label_count=[0,0,0,0,0,0]\n",
    "for i in tqdm(range(0,20)):\n",
    " \n",
    "  tf.keras.backend.clear_session()\n",
    "  terminal= data.columns[i] # Extracting the column names from the dataframe\n",
    "    #num_class=data[terminal].unique() # Unique labels present in the dataframe column\n",
    "  #print(terminal)\n",
    "  weekend=data[terminal].apply(label_encoder)\n",
    "  num_class=weekend.unique()\n",
    "  num_class.sort()\n",
    "  weekend_test=test_data[terminal].apply(label_encoder)\n",
    "  num_class_test=weekend_test.unique()\n",
    "  num_class_test.sort()\n",
    "  if len(num_class)>1:\n",
    "    unit=len(num_class)\n",
    "    #print(unit)\n",
    "    y=np.array(weekend).reshape(-1,1) # label encoding class labels\n",
    "    y_test=np.array(weekend_test).reshape(-1,1)\n",
    "    y_train1 = to_categorical(y, 5)\n",
    "    y_test1 = to_categorical(y_test, 5)\n",
    "    #print(y_train1.shape)\n",
    "    #print(y_test1.shape)   \n",
    "            # define model   \n",
    "    model = T2V_NN(16, 5)\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', mode='auto', verbose=2,patience=5)\n",
    "    model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3))\n",
    "\n",
    "    \n",
    "    #class_weights = class_weight.compute_class_weight('balanced',weekend.unique(y) ,data[terminal])\n",
    "    #class_weights = dict(enumerate(class_weights))\n",
    "    model.fit(X, y_train1, epochs=200, batch_size=50, verbose=0,  shuffle =False, callbacks=[callback])\n",
    "        \n",
    "    y_pred=model.predict(X)     \n",
    "    val_predict=np.argmax(y_pred, axis=1) \n",
    "    val_target=np.argmax(y_train1, axis=1) \n",
    "    state_f1=f1_score(val_target, val_predict, average=None)\n",
    "        \n",
    "    y_pred_test=model.predict(X_test)\n",
    "    val_predict=np.argmax(y_pred_test, axis=1) \n",
    "    val_target=np.argmax(y_test1, axis=1) \n",
    "    state_f1_test=f1_score(val_target, val_predict, average=None)\n",
    "        \n",
    "    idx=0\n",
    "    for label in num_class:\n",
    "            #print(\"more than 1\",num_class)\n",
    "        f1_state_terminal[label]+=state_f1[idx]\n",
    "        label_count[label]+=1\n",
    "        idx+=1\n",
    "            #print('passed from if ')\n",
    "            \n",
    "    idx=0\n",
    "    for label in num_class_test:\n",
    "        f1_state_terminal_test[label]+=state_f1_test[idx]\n",
    "        idx+=1\n",
    "              \n",
    "  else:    \n",
    "    for label in num_class:\n",
    "            #print('1 class',num_class)\n",
    "        f1_state_terminal[label]+=1 # Adding F1 score as 1 to the state where a terminal is in only one mode\n",
    "        label_count[label]+=1\n",
    "            #print('passed from else')\n",
    "        \n",
    "    for label in num_class_test:\n",
    "        f1_state_terminal_test[label]+=1 # Adding F1 score as 1 to the state where a terminal is in only one mode\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cY5_sHawfPmD",
    "outputId": "1306b9d3-1908-43de-be4c-b98420368e39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 82.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "av_count=0\n",
    "ch_count=0\n",
    "pa_count=0\n",
    "do_count=0                             \n",
    "of_count=0\n",
    "for i in tqdm(range(0,20)):\n",
    "    \n",
    "    terminal= data.columns[i] # Extracting the column names from the dataframe\n",
    "    labels=data[terminal]\n",
    "    for i in labels:\n",
    "        #print(i)\n",
    "        if i=='Available':\n",
    "            av_count+=1\n",
    "        if i=='Charging':\n",
    "            ch_count+=1\n",
    "        if i=='Passive':\n",
    "            pa_count+=1\n",
    "        if i=='Down':\n",
    "            do_count+=1\n",
    "        if i=='Offline':\n",
    "            of_count+=1\n",
    "tot_count=av_count+ch_count+pa_count+do_count+of_count\n",
    "print(tot_count)\n",
    "prob_list=[0,0,0,0,0]# order available, passive, charging, offline, down\n",
    "prob_list[0]=av_count/tot_count\n",
    "prob_list[1]=pa_count/tot_count\n",
    "prob_list[2]=ch_count/tot_count\n",
    "prob_list[3]=of_count/tot_count\n",
    "prob_list[4]=do_count/tot_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i50FhqTZIYEU",
    "outputId": "d4a4fd27-88fb-468f-e1f4-ad15a730fe22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S62-T3\n"
     ]
    }
   ],
   "source": [
    "terminal= data.columns[9]\n",
    "print(terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hnCJYgf3fSTJ",
    "outputId": "7f2bd34c-f5af-4e4d-9395-6a9910d4353d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Combined Average F1 scores of train Terminals  [0.6296861068299016, 0.02109978344581388, 0.18010394276039654, 0.3480914015676406, 0.17583498205962242, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.5042944191489462, 0.0, 0.02566527967026292, 0.3845369949516257, 0.15, 0]\n",
      "The final F1 test score is 0.4448228080230197\n",
      "The final F1 test score is 0.37104987217610585\n"
     ]
    }
   ],
   "source": [
    "#print('The counts of the class labels in train data', label_count)\n",
    "#print(\"The Combined F1 scores of Terminals \",f1_state_terminal) # order available, passive, charging, offline, down\n",
    "for i in range(len(f1_state_terminal)-1):\n",
    "    f1_state_terminal[i]/=20\n",
    "print(\"The Combined Average F1 scores of train Terminals \",f1_state_terminal) # order available, passive, charging, offline, down\n",
    "\n",
    "#print(\"The Combined F1 scores of test Terminals \",f1_state_terminal_test) # order available, passive, charging, offline, down\n",
    "for i in range(len(f1_state_terminal)-1):\n",
    "    f1_state_terminal_test[i]/=20\n",
    "print(\"The Combined Average F1 scores of test Terminals \",f1_state_terminal_test) # order available, passive, charging, offline,down\n",
    "\n",
    "f1_final=0\n",
    "#print(\" The probabilities of the train states\",prob_list)\n",
    "for i in range(len(prob_list)):\n",
    "    f1_final+=prob_list[i]*f1_state_terminal[i]\n",
    "print('The final F1 test score is', f1_final)\n",
    "\n",
    "f1_final_test=0\n",
    "\n",
    "for i in range(len(prob_list)):\n",
    "    f1_final_test+=prob_list[i]*f1_state_terminal_test[i]\n",
    "print('The final F1 test score is', f1_final_test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "T2v_LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
