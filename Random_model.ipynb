{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Importing numpy for performing array and matrix operations \n",
    "import pandas as pd # Importing pandas to read data in dataframe\n",
    "\n",
    "# Libraries to plot the distribution of classes \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime #I will use this to Convert ISO8601 format to unix time\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "\n",
    "import time #I will use this to Convert ISO8601 format to unix time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn import linear_model  #Importing linear models like logistics regression and SVC\n",
    "from sklearn.preprocessing import LabelEncoder  # To convert every class  into numeric labels \n",
    "from sklearn.metrics import f1_score       # to calculate F1 score \n",
    "from sklearn.metrics import classification_report # to know every metric\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1= pd.read_csv('ytrain_NpxebDC.csv', parse_dates=['timestamp'],index_col= ['timestamp']) # Reading the csv file in data dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in data1:    # for every column in the data frame\n",
    "    if col!='timestamp':\n",
    "        data1[col]=data1[col].fillna('Offline')  # Filling the missing class label with Down as explained above\n",
    "data1['S7-T1'].isnull().sum() # counting the NAN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, test_data=train_test_split(data1, test_size=0.10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data= pd.read_csv('yrandom.csv', parse_dates=['timestamp'],index_col= ['timestamp']) # Reading the csv file in data dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S7-T1</th>\n",
       "      <th>S2-T1</th>\n",
       "      <th>S19-T1</th>\n",
       "      <th>S56-T3</th>\n",
       "      <th>S85-T3</th>\n",
       "      <th>S16-T3</th>\n",
       "      <th>S16-T1</th>\n",
       "      <th>S94-T3</th>\n",
       "      <th>S28-T1</th>\n",
       "      <th>S62-T3</th>\n",
       "      <th>...</th>\n",
       "      <th>S47-T2</th>\n",
       "      <th>S65-T2</th>\n",
       "      <th>S32-T2</th>\n",
       "      <th>S21-T2</th>\n",
       "      <th>S13-T2</th>\n",
       "      <th>S97-T2</th>\n",
       "      <th>S25-T1</th>\n",
       "      <th>S25-T2</th>\n",
       "      <th>S98-T2</th>\n",
       "      <th>S99-T2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-25 00:00:00+00:00</th>\n",
       "      <td>Down</td>\n",
       "      <td>Down</td>\n",
       "      <td>Available</td>\n",
       "      <td>Down</td>\n",
       "      <td>Down</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Down</td>\n",
       "      <td>...</td>\n",
       "      <td>Down</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Available</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 00:15:00+00:00</th>\n",
       "      <td>Down</td>\n",
       "      <td>Down</td>\n",
       "      <td>Available</td>\n",
       "      <td>Down</td>\n",
       "      <td>Down</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Down</td>\n",
       "      <td>...</td>\n",
       "      <td>Down</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Available</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 00:30:00+00:00</th>\n",
       "      <td>Down</td>\n",
       "      <td>Down</td>\n",
       "      <td>Available</td>\n",
       "      <td>Down</td>\n",
       "      <td>Down</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Down</td>\n",
       "      <td>...</td>\n",
       "      <td>Down</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Available</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 00:45:00+00:00</th>\n",
       "      <td>Down</td>\n",
       "      <td>Down</td>\n",
       "      <td>Available</td>\n",
       "      <td>Down</td>\n",
       "      <td>Down</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Down</td>\n",
       "      <td>...</td>\n",
       "      <td>Down</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Available</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 01:00:00+00:00</th>\n",
       "      <td>Down</td>\n",
       "      <td>Down</td>\n",
       "      <td>Available</td>\n",
       "      <td>Down</td>\n",
       "      <td>Down</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Down</td>\n",
       "      <td>...</td>\n",
       "      <td>Down</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Available</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 273 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          S7-T1 S2-T1     S19-T1 S56-T3 S85-T3   S16-T3  \\\n",
       "timestamp                                                                 \n",
       "2019-11-25 00:00:00+00:00  Down  Down  Available   Down   Down  Offline   \n",
       "2019-11-25 00:15:00+00:00  Down  Down  Available   Down   Down  Offline   \n",
       "2019-11-25 00:30:00+00:00  Down  Down  Available   Down   Down  Offline   \n",
       "2019-11-25 00:45:00+00:00  Down  Down  Available   Down   Down  Offline   \n",
       "2019-11-25 01:00:00+00:00  Down  Down  Available   Down   Down  Offline   \n",
       "\n",
       "                            S16-T1   S94-T3     S28-T1 S62-T3  ... S47-T2  \\\n",
       "timestamp                                                      ...          \n",
       "2019-11-25 00:00:00+00:00  Offline  Offline  Available   Down  ...   Down   \n",
       "2019-11-25 00:15:00+00:00  Offline  Offline  Available   Down  ...   Down   \n",
       "2019-11-25 00:30:00+00:00  Offline  Offline  Available   Down  ...   Down   \n",
       "2019-11-25 00:45:00+00:00  Offline  Offline  Available   Down  ...   Down   \n",
       "2019-11-25 01:00:00+00:00  Offline  Offline  Available   Down  ...   Down   \n",
       "\n",
       "                            S65-T2   S32-T2     S21-T2     S13-T2   S97-T2  \\\n",
       "timestamp                                                                    \n",
       "2019-11-25 00:00:00+00:00  Offline  Offline  Available  Available  Offline   \n",
       "2019-11-25 00:15:00+00:00  Offline  Offline  Available  Available  Offline   \n",
       "2019-11-25 00:30:00+00:00  Offline  Offline  Available  Available  Offline   \n",
       "2019-11-25 00:45:00+00:00  Offline  Offline  Available  Available  Offline   \n",
       "2019-11-25 01:00:00+00:00  Offline  Offline  Available  Available  Offline   \n",
       "\n",
       "                            S25-T1   S25-T2   S98-T2   S99-T2  \n",
       "timestamp                                                      \n",
       "2019-11-25 00:00:00+00:00  Offline  Offline  Offline  Offline  \n",
       "2019-11-25 00:15:00+00:00  Offline  Offline  Offline  Offline  \n",
       "2019-11-25 00:30:00+00:00  Offline  Offline  Offline  Offline  \n",
       "2019-11-25 00:45:00+00:00  Offline  Offline  Offline  Offline  \n",
       "2019-11-25 01:00:00+00:00  Offline  Offline  Offline  Offline  \n",
       "\n",
       "[5 rows x 273 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S7-T1</th>\n",
       "      <th>S2-T1</th>\n",
       "      <th>S19-T1</th>\n",
       "      <th>S56-T3</th>\n",
       "      <th>S85-T3</th>\n",
       "      <th>S16-T3</th>\n",
       "      <th>S16-T1</th>\n",
       "      <th>S94-T3</th>\n",
       "      <th>S28-T1</th>\n",
       "      <th>S62-T3</th>\n",
       "      <th>...</th>\n",
       "      <th>S47-T2</th>\n",
       "      <th>S65-T2</th>\n",
       "      <th>S32-T2</th>\n",
       "      <th>S21-T2</th>\n",
       "      <th>S13-T2</th>\n",
       "      <th>S97-T2</th>\n",
       "      <th>S25-T1</th>\n",
       "      <th>S25-T2</th>\n",
       "      <th>S98-T2</th>\n",
       "      <th>S99-T2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-10-02 04:45:00+00:00</th>\n",
       "      <td>Down</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Available</td>\n",
       "      <td>Down</td>\n",
       "      <td>Available</td>\n",
       "      <td>Charging</td>\n",
       "      <td>Available</td>\n",
       "      <td>Available</td>\n",
       "      <td>Down</td>\n",
       "      <td>...</td>\n",
       "      <td>Down</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Passive</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Passive</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-02 05:00:00+00:00</th>\n",
       "      <td>Down</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Available</td>\n",
       "      <td>Down</td>\n",
       "      <td>Available</td>\n",
       "      <td>Charging</td>\n",
       "      <td>Available</td>\n",
       "      <td>Available</td>\n",
       "      <td>Down</td>\n",
       "      <td>...</td>\n",
       "      <td>Down</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Passive</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Passive</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-02 05:15:00+00:00</th>\n",
       "      <td>Down</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Available</td>\n",
       "      <td>Down</td>\n",
       "      <td>Available</td>\n",
       "      <td>Charging</td>\n",
       "      <td>Available</td>\n",
       "      <td>Available</td>\n",
       "      <td>Down</td>\n",
       "      <td>...</td>\n",
       "      <td>Down</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Passive</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Passive</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-02 05:30:00+00:00</th>\n",
       "      <td>Down</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Available</td>\n",
       "      <td>Down</td>\n",
       "      <td>Available</td>\n",
       "      <td>Charging</td>\n",
       "      <td>Available</td>\n",
       "      <td>Available</td>\n",
       "      <td>Down</td>\n",
       "      <td>...</td>\n",
       "      <td>Down</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Passive</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Passive</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-02 05:45:00+00:00</th>\n",
       "      <td>Down</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Available</td>\n",
       "      <td>Down</td>\n",
       "      <td>Available</td>\n",
       "      <td>Charging</td>\n",
       "      <td>Available</td>\n",
       "      <td>Available</td>\n",
       "      <td>Down</td>\n",
       "      <td>...</td>\n",
       "      <td>Down</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Passive</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Passive</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Offline</td>\n",
       "      <td>Available</td>\n",
       "      <td>Available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 273 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          S7-T1    S2-T1     S19-T1     S56-T3 S85-T3  \\\n",
       "timestamp                                                               \n",
       "2020-10-02 04:45:00+00:00  Down  Offline  Available  Available   Down   \n",
       "2020-10-02 05:00:00+00:00  Down  Offline  Available  Available   Down   \n",
       "2020-10-02 05:15:00+00:00  Down  Offline  Available  Available   Down   \n",
       "2020-10-02 05:30:00+00:00  Down  Offline  Available  Available   Down   \n",
       "2020-10-02 05:45:00+00:00  Down  Offline  Available  Available   Down   \n",
       "\n",
       "                              S16-T3    S16-T1     S94-T3     S28-T1 S62-T3  \\\n",
       "timestamp                                                                     \n",
       "2020-10-02 04:45:00+00:00  Available  Charging  Available  Available   Down   \n",
       "2020-10-02 05:00:00+00:00  Available  Charging  Available  Available   Down   \n",
       "2020-10-02 05:15:00+00:00  Available  Charging  Available  Available   Down   \n",
       "2020-10-02 05:30:00+00:00  Available  Charging  Available  Available   Down   \n",
       "2020-10-02 05:45:00+00:00  Available  Charging  Available  Available   Down   \n",
       "\n",
       "                           ... S47-T2   S65-T2   S32-T2   S21-T2     S13-T2  \\\n",
       "timestamp                  ...                                                \n",
       "2020-10-02 04:45:00+00:00  ...   Down  Offline  Passive  Offline  Available   \n",
       "2020-10-02 05:00:00+00:00  ...   Down  Offline  Passive  Offline  Available   \n",
       "2020-10-02 05:15:00+00:00  ...   Down  Offline  Passive  Offline  Available   \n",
       "2020-10-02 05:30:00+00:00  ...   Down  Offline  Passive  Offline  Available   \n",
       "2020-10-02 05:45:00+00:00  ...   Down  Offline  Passive  Offline  Available   \n",
       "\n",
       "                            S97-T2   S25-T1   S25-T2     S98-T2     S99-T2  \n",
       "timestamp                                                                   \n",
       "2020-10-02 04:45:00+00:00  Passive  Offline  Offline  Available  Available  \n",
       "2020-10-02 05:00:00+00:00  Passive  Offline  Offline  Available  Available  \n",
       "2020-10-02 05:15:00+00:00  Passive  Offline  Offline  Available  Available  \n",
       "2020-10-02 05:30:00+00:00  Passive  Offline  Offline  Available  Available  \n",
       "2020-10-02 05:45:00+00:00  Passive  Offline  Offline  Available  Available  \n",
       "\n",
       "[5 rows x 273 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_time(data):\n",
    "# Initializing Empty lists\n",
    "    year=[]\n",
    "    month=[]\n",
    "    week=[]\n",
    "    date=[]\n",
    "    hr=[]\n",
    "    minute=[]\n",
    "\n",
    "# I have made timestamp column as an index of the dataframe for easy plotting operations\n",
    "    for i in data.index: # For every index of the dataframe\n",
    "    #print(i)\n",
    "    #break\n",
    "    #dt = datetime.datetime.strptime(i, \"%Y-%m-%dT%H:%M:%S%z\")\n",
    "        dt=i\n",
    "    # Appending the month, day, weekday, hour and minute in lists\n",
    "        year.append(dt.year)\n",
    "        month.append(dt.month)\n",
    "        week.append(dt.weekday()) #Monday is 0 and Sunday is 6\n",
    "        date.append(dt.day)\n",
    "        hr.append(dt.hour)\n",
    "        minute.append(dt.minute)\n",
    "# making X as a data frame \n",
    "    return pd.DataFrame(list(zip(year, month, week, date, hr, minute)), columns =['year','Month_name', 'Week_number', 'Date', 'Hour', 'Minute'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Month_name</th>\n",
       "      <th>Week_number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  Month_name  Week_number  Date  Hour  Minute\n",
       "0  2019          11            0    25     0       0\n",
       "1  2019          11            0    25     0      15\n",
       "2  2019          11            0    25     0      30\n",
       "3  2019          11            0    25     0      45\n",
       "4  2019          11            0    25     1       0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=date_time(data)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Month_name</th>\n",
       "      <th>Week_number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  Month_name  Week_number  Date  Hour  Minute\n",
       "0  2020          10            4     2     4      45\n",
       "1  2020          10            4     2     5       0\n",
       "2  2020          10            4     2     5      15\n",
       "3  2020          10            4     2     5      30\n",
       "4  2020          10            4     2     5      45"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=date_time(test_data)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daypart function\n",
    "def DayPart(hour):\n",
    "    if hour in [2,3,4,5]: # dawn ==1\n",
    "        return 1\n",
    "    elif hour in [6,7,8,9]: # morning ==2\n",
    "        return 2\n",
    "    elif hour in [10,11,12,13]: #  noon==3\n",
    "        return 3\n",
    "    elif hour in [14,15,16,17]: # Afternoon==4\n",
    "        return 4\n",
    "    elif hour in [18,19,20,21]:  # evening ==5\n",
    "        return 5\n",
    "    else: return 6    # midnight==6\n",
    "# utilize it along with apply method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28108,)\n",
      "(3124,)\n"
     ]
    }
   ],
   "source": [
    "dayparts = X['Hour'].apply(DayPart)\n",
    "dayparts_test=X_test['Hour'].apply(DayPart)\n",
    "print(dayparts.shape)\n",
    "print(dayparts_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28108, 6)\n",
      "(3124, 6)\n"
     ]
    }
   ],
   "source": [
    "# one hot encoding\n",
    "daypart_ohe= pd.get_dummies(dayparts)\n",
    "daypart_test_ohe=pd.get_dummies(dayparts_test)\n",
    "print(daypart_ohe.shape)\n",
    "print(daypart_test_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28108, 7)\n",
      "(3124, 7)\n"
     ]
    }
   ],
   "source": [
    "# one hot encoding\n",
    "week_number_ohe= pd.get_dummies(X['Week_number'])\n",
    "week_number_test_ohe=pd.get_dummies(X_test['Week_number'])\n",
    "print(week_number_ohe.shape)\n",
    "print(week_number_test_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is weekend\n",
    "def IsWeekEnd(number):\n",
    "    if number in [5,6]: # if staurday or sunday return 1\n",
    "        return 1\n",
    "    else: return 0    # weekdays=6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28108,)\n",
      "(3124,)\n"
     ]
    }
   ],
   "source": [
    "weekend=X['Week_number'].apply(IsWeekEnd)\n",
    "weekend_test=X_test['Week_number'].apply(IsWeekEnd)\n",
    "print(weekend.shape)\n",
    "print(weekend_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=X.drop(['Week_number'], axis=1)\n",
    "x_test=X_test.drop(['Week_number'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28108, 19)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge two sparse matrices: https://stackoverflow.com/a/19710648/4084039 \n",
    "X_tr = pd.concat([x,daypart_ohe, week_number_ohe, weekend], axis = 1)\n",
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3124, 19)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_te=pd.concat([x_test,daypart_test_ohe, week_number_test_ohe, weekend_test], axis = 1)\n",
    "X_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def label_encoder(column):\n",
    "    '''\n",
    "    This function help us to Encode the class labels of \n",
    "    the corresponding terminal into their respective \n",
    "    numeric labels\n",
    "    '''\n",
    "    if column =='Available': # Available ==0\n",
    "        return 0\n",
    "    elif column=='Charging': # charging==1\n",
    "        return 1\n",
    "    elif column=='Passive': # Passive==2\n",
    "        return 2\n",
    "    elif column=='Offline': # offline==3\n",
    "        return 3\n",
    "    else: return 4    # Down==4\n",
    "# utilize it along with apply method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "weekend=data['S19-T1'].apply(label_encoder)\n",
    "num=weekend.unique()\n",
    "for i in num:\n",
    "    print(type(i))\n",
    "print(np.array(weekend).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [00:05<00:00, 51.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7673484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "av_count=0\n",
    "ch_count=0\n",
    "pa_count=0\n",
    "do_count=0\n",
    "of_count=0\n",
    "for i in tqdm(range(0,data.shape[1])):\n",
    "    \n",
    "    terminal= data.columns[i] # Extracting the column names from the dataframe\n",
    "    labels=data[terminal]\n",
    "    for i in labels:\n",
    "        #print(i)\n",
    "        if i=='Available':\n",
    "            av_count+=1\n",
    "        if i=='Charging':\n",
    "            ch_count+=1\n",
    "        if i=='Passive':\n",
    "            pa_count+=1\n",
    "        if i=='Down':\n",
    "            do_count+=1\n",
    "        if i=='Offline':\n",
    "            of_count+=1\n",
    "tot_count=av_count+ch_count+pa_count+do_count+of_count\n",
    "print(tot_count)\n",
    "prob_list=[0,0,0,0,0]# order available, passive, charging, offline, down\n",
    "prob_list[0]=av_count/tot_count\n",
    "prob_list[1]=pa_count/tot_count\n",
    "prob_list[2]=ch_count/tot_count\n",
    "prob_list[3]=of_count/tot_count\n",
    "prob_list[4]=do_count/tot_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5967492732114904, 0.0699189572819856, 0.05761789559996476, 0.1853876283576013, 0.09032624554895795]\n"
     ]
    }
   ],
   "source": [
    "print(prob_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_func(num_class):\n",
    "    dct={}\n",
    "    for num in num_class:\n",
    "        if num==0:  # Available\n",
    "            dct[0]=1\n",
    "        if num==1:    #Charging\n",
    "            dct[1]=9\n",
    "        if num==2:    # Passive\n",
    "            dct[2]=10\n",
    "        if num==3:     # Offline\n",
    "            dct[3]=3\n",
    "        if num==4:     # down\n",
    "            dct[4]=5\n",
    "    return dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [08:15<00:00,  1.81s/it]\n"
     ]
    }
   ],
   "source": [
    "f1_state_terminal=[0,0,0,0,0, 0] # order available, passive, charging, offline, down\n",
    "f1_state_terminal_test=[0,0,0,0,0, 0] # order available, passive, charging, offline, down\n",
    "label_count=[0,0,0,0,0,0]\n",
    "for i in tqdm(range(0,data.shape[1])):\n",
    "    \n",
    "    terminal= data.columns[i] # Extracting the column names from the dataframe\n",
    "    #num_class=data[terminal].unique() # Unique labels present in the dataframe column\n",
    "    weekend=data[terminal].apply(label_encoder)\n",
    "    num_class=weekend.unique()\n",
    "    \n",
    "    weekend_test=test_data[terminal].apply(label_encoder)\n",
    "    num_class_test=weekend_test.unique()\n",
    "    num_class_test.sort()\n",
    "    num_class.sort()\n",
    "    if len(num_class)>1:\n",
    "        \n",
    "        y=np.array(weekend).reshape(-1,1) # label encoding class labels\n",
    "        y_test=np.array(weekend_test).reshape(-1,1)\n",
    "        #print(y)\n",
    "        if len(num_class)>2:\n",
    "            clf = linear_model.LogisticRegression(multi_class='ovr', class_weight=weight_func(num_class)) # initializing logistics regression in multiclass setting\n",
    "        else:\n",
    "             clf = linear_model.LogisticRegression(class_weight=weight_func(num_class)) # initializing logistics regression in multiclass settingticlass setting\n",
    "        \n",
    "        clf.fit(X_tr, y) # fitting our model\n",
    "        \n",
    "        y_pred=clf.predict(X_tr)\n",
    "        state_f1=f1_score(y, y_pred, average=None)\n",
    "        \n",
    "        y_pred_test=clf.predict(X_te)\n",
    "        state_f1_test=f1_score(y_test, y_pred_test, average=None)\n",
    "        \n",
    "        idx=0\n",
    "        for label in num_class:\n",
    "            #print(\"more than 1\",num_class)\n",
    "            f1_state_terminal[label]+=state_f1[idx]\n",
    "            label_count[label]+=1\n",
    "            idx+=1\n",
    "            #print('passed from if ')\n",
    "            \n",
    "            idx=0\n",
    "        for label in num_class_test:\n",
    "            f1_state_terminal_test[label]+=state_f1_test[idx]\n",
    "            idx+=1\n",
    "         \n",
    "    else:\n",
    "        for label in num_class:\n",
    "            #print('1 class',num_class)\n",
    "            f1_state_terminal[label]+=1 # Adding F1 score as 1 to the state where a terminal is in only one mode\n",
    "            label_count[label]+=1\n",
    "            #print('passed from else')\n",
    "        \n",
    "        for label in num_class_test:\n",
    "            f1_state_terminal_test[label]+=1 # Adding F1 score as 1 to the state where a terminal is in only one mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Combined Average F1 scores of train Terminals  [0.2798138172518954, 0.22369435766693058, 0.2285317659698439, 0.2285317659698439, 0.1617985010298068, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.23557217986392887, 0.12484561364743865, 0.09564076345781318, 0.22818877004404212, 0.06694784679167977, 0]\n",
      "The final F1 score is 0.25276830098145814\n",
      "The final F1 score is 0.20316774431870013\n"
     ]
    }
   ],
   "source": [
    "#print('The counts of the class labels in train data', label_count)\n",
    "#print(\"The Combined F1 scores of Terminals \",f1_state_terminal) # order available, passive, charging, offline, down\n",
    "for i in range(len(label_count)-1):\n",
    "    f1_state_terminal[i]/=273\n",
    "print(\"The Combined Average F1 scores of train Terminals \",f1_state_terminal) # order available, passive, charging, offline, down\n",
    "\n",
    "#print(\"The Combined F1 scores of test Terminals \",f1_state_terminal_test) # order available, passive, charging, offline, down\n",
    "for i in range(len(label_count)-1):\n",
    "    f1_state_terminal_test[i]/=273\n",
    "print(\"The Combined Average F1 scores of test Terminals \",f1_state_terminal_test) # order available, passive, charging, offline,down\n",
    "\n",
    "f1_final=0\n",
    "#print(\" The probabilities of the train states\",prob_list)\n",
    "for i in range(len(prob_list)):\n",
    "    f1_final+=prob_list[i]*f1_state_terminal[i]\n",
    "print('The final F1 score is', f1_final)\n",
    "\n",
    "f1_final_test=0\n",
    "\n",
    "for i in range(len(prob_list)):\n",
    "    f1_final_test+=prob_list[i]*f1_state_terminal_test[i]\n",
    "print('The final F1 score is', f1_final_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistisc Regression with L2 regulerization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [08:08<00:00,  1.79s/it]\n"
     ]
    }
   ],
   "source": [
    "f1_state_terminal=[0,0,0,0,0, 0] # order available, passive, charging, offline, down\n",
    "f1_state_terminal_test=[0,0,0,0,0, 0] # order available, passive, charging, offline, down\n",
    "label_count=[0,0,0,0,0,0]\n",
    "for i in tqdm(range(0,data.shape[1])):\n",
    "    \n",
    "    terminal= data.columns[i] # Extracting the column names from the dataframe\n",
    "    #num_class=data[terminal].unique() # Unique labels present in the dataframe column\n",
    "    weekend=data[terminal].apply(label_encoder)\n",
    "    num_class=weekend.unique()\n",
    "    \n",
    "    weekend_test=test_data[terminal].apply(label_encoder)\n",
    "    num_class_test=weekend_test.unique()\n",
    "    num_class_test.sort()\n",
    "    num_class.sort()\n",
    "    if len(num_class)>1:\n",
    "        \n",
    "        y=np.array(weekend).reshape(-1,1) # label encoding class labels\n",
    "        y_test=np.array(weekend_test).reshape(-1,1)\n",
    "        #print(y)\n",
    "        if len(num_class)>2:\n",
    "            clf = linear_model.LogisticRegression(multi_class='ovr', penalty='l2', class_weight=weight_func(num_class)) # initializing logistics regression in multiclass setting\n",
    "        else:\n",
    "             clf = linear_model.LogisticRegression(penalty='l2', class_weight=weight_func(num_class)) # initializing logistics regression in multiclass settingticlass setting\n",
    "        \n",
    "        clf.fit(X_tr, y) # fitting our model\n",
    "        \n",
    "        y_pred=clf.predict(X_tr)\n",
    "        state_f1=f1_score(y, y_pred, average=None)\n",
    "        \n",
    "        y_pred_test=clf.predict(X_te)\n",
    "        state_f1_test=f1_score(y_test, y_pred_test, average=None)\n",
    "        \n",
    "        idx=0\n",
    "        for label in num_class:\n",
    "            #print(\"more than 1\",num_class)\n",
    "            f1_state_terminal[label]+=state_f1[idx]\n",
    "            label_count[label]+=1\n",
    "            idx+=1\n",
    "            #print('passed from if ')\n",
    "            \n",
    "            idx=0\n",
    "        for label in num_class_test:\n",
    "            f1_state_terminal_test[label]+=state_f1_test[idx]\n",
    "            idx+=1\n",
    "         \n",
    "    else:\n",
    "        for label in num_class:\n",
    "            #print('1 class',num_class)\n",
    "            f1_state_terminal[label]+=1 # Adding F1 score as 1 to the state where a terminal is in only one mode\n",
    "            label_count[label]+=1\n",
    "            #print('passed from else')\n",
    "        \n",
    "        for label in num_class_test:\n",
    "            f1_state_terminal_test[label]+=1 # Adding F1 score as 1 to the state where a terminal is in only one mode\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Combined Average F1 scores of train Terminals  [0.2798138172518954, 0.22369435766693058, 0.2285317659698439, 0.2285317659698439, 0.1617985010298068, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.23557217986392887, 0.12484561364743865, 0.09564076345781318, 0.22818877004404212, 0.06694784679167977, 0]\n",
      "The final F1 score is 0.25276830098145814\n",
      "The final F1 score is 0.20316774431870013\n"
     ]
    }
   ],
   "source": [
    "#print('The counts of the class labels in train data', label_count)\n",
    "#print(\"The Combined F1 scores of Terminals \",f1_state_terminal) # order available, passive, charging, offline, down\n",
    "for i in range(len(label_count)-1):\n",
    "    f1_state_terminal[i]/=273\n",
    "print(\"The Combined Average F1 scores of train Terminals \",f1_state_terminal) # order available, passive, charging, offline, down\n",
    "\n",
    "#print(\"The Combined F1 scores of test Terminals \",f1_state_terminal_test) # order available, passive, charging, offline, down\n",
    "for i in range(len(label_count)-1):\n",
    "    f1_state_terminal_test[i]/=273\n",
    "print(\"The Combined Average F1 scores of test Terminals \",f1_state_terminal_test) # order available, passive, charging, offline,down\n",
    "\n",
    "f1_final=0\n",
    "#print(\" The probabilities of the train states\",prob_list)\n",
    "for i in range(len(prob_list)):\n",
    "    f1_final+=prob_list[i]*f1_state_terminal[i]\n",
    "print('The final F1 score is', f1_final)\n",
    "\n",
    "f1_final_test=0\n",
    "\n",
    "for i in range(len(prob_list)):\n",
    "    f1_final_test+=prob_list[i]*f1_state_terminal_test[i]\n",
    "print('The final F1 score is', f1_final_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResults():\n",
    "    #print('The counts of the class labels in train data', label_count)\n",
    "    #print(\"The Combined F1 scores of Terminals \",f1_state_terminal) # order available, passive, charging, offline, down\n",
    "    for i in range(len(label_count)-1):\n",
    "        f1_state_terminal[i]/=data.shape[1]\n",
    "    print(\"The Combined Average F1 scores of train Terminals \",f1_state_terminal) # order available, passive, charging, offline, down\n",
    "\n",
    "    #print(\"The Combined F1 scores of test Terminals \",f1_state_terminal_test) # order available, passive, charging, offline, down\n",
    "    for i in range(len(label_count)-1):\n",
    "        f1_state_terminal_test[i]/=data.shape[1]\n",
    "    print(\"The Combined Average F1 scores of test Terminals \",f1_state_terminal_test) # order available, passive, charging, offline, down\n",
    "\n",
    "    f1_final=0\n",
    "    #print(\" The probabilities of the train states\",prob_list)\n",
    "    for i in range(len(prob_list)):\n",
    "        f1_final+=prob_list[i]*f1_state_terminal[i]\n",
    "    print('The final train F1 score is', f1_final)\n",
    "\n",
    "\n",
    "    f1_final_test=0\n",
    "\n",
    "    for i in range(len(prob_list)):\n",
    "        f1_final_test+=prob_list[i]*f1_state_terminal_test[i]\n",
    "    print('The final test F1 score is', f1_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [00:35<00:00,  7.59it/s]\n"
     ]
    }
   ],
   "source": [
    "f1_state_terminal=[0,0,0,0,0, 0] # order available, passive, charging, offline, down\n",
    "f1_state_terminal_test=[0,0,0,0,0, 0] # order available, passive, charging, offline, down\n",
    "label_count=[0,0,0,0,0,0]\n",
    "for i in tqdm(range(0,data.shape[1])):\n",
    "    \n",
    "    terminal= data.columns[i] # Extracting the column names from the dataframe\n",
    "    #num_class=data[terminal].unique() # Unique labels present in the dataframe column\n",
    "    weekend=data[terminal].apply(label_encoder)\n",
    "    num_class=weekend.unique()\n",
    "    \n",
    "    weekend_test=test_data[terminal].apply(label_encoder)\n",
    "    num_class_test=weekend_test.unique()\n",
    "    num_class_test.sort()\n",
    "    num_class.sort()\n",
    "    if len(num_class)>1:\n",
    "        \n",
    "        y=np.array(weekend).reshape(-1,1) # label encoding class labels\n",
    "        y_test=np.array(weekend_test).reshape(-1,1)\n",
    "        #print(y)\n",
    "        \n",
    "        clf = DecisionTreeClassifier(class_weight=weight_func(num_class))  # Decision tree Classifier Initialization with default parameters # initializing logistics regression in multiclass setting\n",
    "        clf.fit(X_tr, y) # fitting our model\n",
    "        \n",
    "        y_pred=clf.predict(X_tr)\n",
    "        state_f1=f1_score(y, y_pred, average=None)\n",
    "        \n",
    "        y_pred_test=clf.predict(X_te)\n",
    "        state_f1_test=f1_score(y_test, y_pred_test, average=None)\n",
    "        \n",
    "        idx=0\n",
    "        for label in num_class:\n",
    "            #print(\"more than 1\",num_class)\n",
    "            f1_state_terminal[label]+=state_f1[idx]\n",
    "            label_count[label]+=1\n",
    "            idx+=1\n",
    "            #print('passed from if ')\n",
    "            \n",
    "            idx=0\n",
    "        for label in num_class_test:\n",
    "            f1_state_terminal_test[label]+=state_f1_test[idx]\n",
    "            idx+=1\n",
    "          \n",
    "    else:\n",
    "        for label in num_class:\n",
    "            #print('1 class',num_class)\n",
    "            f1_state_terminal[label]+=1 # Adding F1 score as 1 to the state where a terminal is in only one mode\n",
    "            label_count[label]+=1\n",
    "            #print('passed from else')\n",
    "        \n",
    "        for label in num_class_test:\n",
    "            f1_state_terminal_test[label]+=1 # Adding F1 score as 1 to the state where a terminal is in only one mode\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Combined Average F1 scores of train Terminals  [0.945054945054945, 0.8717948717948718, 0.8901098901098901, 0.8937728937728938, 0.4945054945054945, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.555323866821481, 0.09583763866111653, 0.06580047156581047, 0.23356596031407725, 0.06551623502944692, 0]\n",
      "The final train F1 score is 0.8865633605158704\n",
      "The final test F1 score is 0.39109934136777913\n"
     ]
    }
   ],
   "source": [
    " printResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameter tuning Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:15<02:04, 15.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the F1 score for 1 depth\n",
      "The Combined Average F1 scores of train Terminals  [0.23231352439832645, 0.1749539657960583, 0.17886243067707658, 0.18103147311627515, 0.14857753764929996, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.188965561297045, 0.07094169892425745, 0.06940048790771876, 0.2340417439956093, 0.06735765737782207, 0]\n",
      "The final train F1 score is 0.20815264916809678\n",
      "The final test F1 score is 0.17119654920539776\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 2/9 [00:33<01:55, 16.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the F1 score for 2 depth\n",
      "The Combined Average F1 scores of train Terminals  [0.3478172709122296, 0.28703171351874224, 0.2933365821666563, 0.29653521963017837, 0.21051113456872592, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.26028855446980675, 0.09290926387609526, 0.06432639884860497, 0.24927405602173552, 0.06173292646480311, 0]\n",
      "The final train F1 score is 0.3185187398338817\n",
      "The final test F1 score is 0.2173179058216256\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 3/9 [00:54<01:45, 17.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the F1 score for 3 depth\n",
      "The Combined Average F1 scores of train Terminals  [0.4176386144105366, 0.3532415881236454, 0.36315792566496324, 0.36635656312848536, 0.2346449225265218, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.2650049116605322, 0.10862290445741248, 0.07408119597292444, 0.23156076852724525, 0.06471680522959775, 0]\n",
      "The final train F1 score is 0.38396078783262166\n",
      "The final test F1 score is 0.21877881900123158\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 4/9 [01:15<01:33, 18.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the F1 score for 4 depth\n",
      "The Combined Average F1 scores of train Terminals  [0.49297577161790224, 0.4282950522530557, 0.43804694211706285, 0.44169372033585114, 0.2785125973639875, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.2921645083956848, 0.11195467751434532, 0.07633629307412947, 0.22624563159599276, 0.06469379038313412, 0]\n",
      "The final train F1 score is 0.4564097683966954\n",
      "The final test F1 score is 0.23436173718628328\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 5/9 [01:38<01:19, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the F1 score for 5 depth\n",
      "The Combined Average F1 scores of train Terminals  [0.5372158639863192, 0.47049675059354557, 0.4822870344854796, 0.48593381270426783, 0.29429361125620496, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.30035615713853564, 0.1193792328474318, 0.08615862058336603, 0.21496576537939405, 0.06221118645991058, 0]\n",
      "The final train F1 score is 0.4979367366696116\n",
      "The final test F1 score is 0.23801976469047478\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 6/9 [02:04<01:05, 21.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the F1 score for 6 depth\n",
      "The Combined Average F1 scores of train Terminals  [0.5871723785103766, 0.5194038578211768, 0.5322387416321291, 0.5358903272283256, 0.3187614220699425, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.3327343742258428, 0.12183761006099951, 0.08793233055403302, 0.22673497950390714, 0.06325740899794477, 0]\n",
      "The final train F1 score is 0.5455173018287062\n",
      "The final test F1 score is 0.25989189486054776\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 7/9 [02:31<00:46, 23.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the F1 score for 7 depth\n",
      "The Combined Average F1 scores of train Terminals  [0.6348609529235646, 0.56638661634568, 0.5799273160453172, 0.5835789016415137, 0.34585791360986934, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.36287961629934046, 0.12453190312271346, 0.0926776792155672, 0.22566154883070966, 0.06300946592549758, 0]\n",
      "The final train F1 score is 0.5912965207969496\n",
      "The final test F1 score is 0.27812144879039036\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 8/9 [02:57<00:24, 24.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the F1 score for 8 depth\n",
      "The Combined Average F1 scores of train Terminals  [0.6781489836440577, 0.6084708896234219, 0.6232162295028603, 0.6268669323620062, 0.36664207319929415, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.3875658010919957, 0.1261290201902694, 0.0920817390872395, 0.21477451924601668, 0.06276636400752808, 0]\n",
      "The final train F1 score is 0.6324677467240893\n",
      "The final test F1 score is 0.29088996448959364\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [03:26<00:00, 22.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the F1 score for 9 depth\n",
      "The Combined Average F1 scores of train Terminals  [0.7172918840892484, 0.6467922087308113, 0.662359129948051, 0.666009832807197, 0.38523811090239335, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.40881950673170686, 0.12507788024683927, 0.09200406832802745, 0.21998394835348123, 0.06602992934690814, 0]\n",
      "The final train F1 score is 0.6696972820895157\n",
      "The final test F1 score is 0.30475567736018455\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for depth in tqdm(range(1, 10, 1)):\n",
    "    f1_state_terminal=[0,0,0,0,0, 0] # order available, passive, charging, offline, down\n",
    "    f1_state_terminal_test=[0,0,0,0,0, 0] # order available, passive, charging, offline, down\n",
    "    label_count=[0,0,0,0,0,0]\n",
    "    for i in range(0,data.shape[1]):\n",
    "    \n",
    "        terminal= data.columns[i] # Extracting the column names from the dataframe\n",
    "    #num_class=data[terminal].unique() # Unique labels present in the dataframe column\n",
    "        weekend=data[terminal].apply(label_encoder)\n",
    "        num_class=weekend.unique()\n",
    "    \n",
    "        weekend_test=test_data[terminal].apply(label_encoder)\n",
    "        num_class_test=weekend_test.unique()\n",
    "        num_class_test.sort()\n",
    "        num_class.sort()\n",
    "        if len(num_class)>1:\n",
    "            \n",
    "            #weight=weight_func(num_class)\n",
    "            y=np.array(weekend).reshape(-1,1) # label encoding class labels\n",
    "            y_test=np.array(weekend_test).reshape(-1,1)\n",
    "        #print(y)\n",
    "            #class_weight={0:1,1:2, 2:2,3:2}\n",
    "            clf = DecisionTreeClassifier(max_depth=depth, min_samples_split=5, min_samples_leaf =5,class_weight= weight_func(num_class))  # Decision tree Classifier Initialization with default parameters # initializing logistics regression in multiclass setting\n",
    "            clf.fit(X_tr, y) # fitting our model\n",
    "        \n",
    "            y_pred=clf.predict(X_tr)\n",
    "            state_f1=f1_score(y, y_pred, average=None)\n",
    "        \n",
    "            y_pred_test=clf.predict(X_te)\n",
    "            state_f1_test=f1_score(y_test, y_pred_test, average=None)\n",
    "        \n",
    "            idx=0\n",
    "            for label in num_class:\n",
    "            #print(\"more than 1\",num_class)\n",
    "                f1_state_terminal[label]+=state_f1[idx]\n",
    "                label_count[label]+=1\n",
    "                idx+=1\n",
    "            #print('passed from if ')\n",
    "            \n",
    "                idx=0\n",
    "            for label in num_class_test:\n",
    "                f1_state_terminal_test[label]+=state_f1_test[idx]\n",
    "                idx+=1\n",
    "          \n",
    "        else:\n",
    "            for label in num_class:\n",
    "            #print('1 class',num_class)\n",
    "                f1_state_terminal[label]+=1 # Adding F1 score as 1 to the state where a terminal is in only one mode\n",
    "                label_count[label]+=1\n",
    "            #print('passed from else')\n",
    "        \n",
    "            for label in num_class_test:\n",
    "                f1_state_terminal_test[label]+=1 # Adding F1 score as 1 to the state where a terminal is in only one mode\n",
    "    \n",
    "    print(\"the F1 score for {0} depth\".format(depth))\n",
    "    printResults()\n",
    "    print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:19<02:56, 19.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with 1 Estimators\n",
      "The Combined Average F1 scores of train Terminals  [0.26705463445738786, 0.21051998607957564, 0.21257394571181465, 0.21577258317533668, 0.16169754861761165, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.24321744017518263, 0.09895450671103798, 0.06579524264924998, 0.22012443828198702, 0.05972890852285108, 0]\n",
      "The final train F1 score is 0.24093916028577228\n",
      "The final test F1 score is 0.20205304562068027\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [01:00<03:28, 26.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with 11 Estimators\n",
      "The Combined Average F1 scores of train Terminals  [0.24943775623039482, 0.19149758524159458, 0.19702731088665673, 0.19815570494834353, 0.14835491594979994, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.21787182513241268, 0.10411193624641311, 0.0768983542047895, 0.24646895918348322, 0.06736565239045861, 0]\n",
      "The final train F1 score is 0.22372936900549134\n",
      "The final test F1 score is 0.1935021549345453\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [02:07<04:27, 38.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with 21 Estimators\n",
      "The Combined Average F1 scores of train Terminals  [0.24686122478309871, 0.18977795512550316, 0.19341013106184882, 0.19557917350104745, 0.1467044040948533, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.2087729163802354, 0.10350571977604049, 0.07527262773913253, 0.2476006953700543, 0.06749120206667199, 0]\n",
      "The final train F1 score is 0.22123643510927654\n",
      "The final test F1 score is 0.18815748110683506\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [03:44<05:35, 55.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with 31 Estimators\n",
      "The Combined Average F1 scores of train Terminals  [0.25013643770462124, 0.19226171861472519, 0.19668534398337145, 0.19885438642257008, 0.1457643658175256, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.2101998886960965, 0.10078910762652064, 0.07494533441061475, 0.2424565965414855, 0.06711531701632162, 0]\n",
      "The final train F1 score is 0.22407556289691333\n",
      "The final test F1 score is 0.18781262059032938\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [05:41<06:11, 74.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with 41 Estimators\n",
      "The Combined Average F1 scores of train Terminals  [0.2468883159785399, 0.18933635107164518, 0.19560626469648867, 0.19560626469648867, 0.1415036234151125, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.21005221035857238, 0.10056186576626774, 0.07401489144903586, 0.247650806710606, 0.06740488564717044, 0]\n",
      "The final train F1 score is 0.22088351724372118\n",
      "The final test F1 score is 0.1886440929220986\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [07:57<06:11, 92.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with 51 Estimators\n",
      "The Combined Average F1 scores of train Terminals  [0.24249237373565155, 0.1853704549914317, 0.18904128001440168, 0.1912103224536003, 0.14065186175679242, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.20499146728951637, 0.1013861135116452, 0.07498247685003921, 0.2465248106943651, 0.0673336172202573, 0]\n",
      "The final train F1 score is 0.2167128002450481\n",
      "The final test F1 score is 0.185522295810827\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [10:52<05:52, 117.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with 61 Estimators\n",
      "The Combined Average F1 scores of train Terminals  [0.254081909762601, 0.19728383892654505, 0.20063081604135116, 0.2027998584805498, 0.1496603553850038, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.2171032605026088, 0.09960032837582013, 0.07774451861498996, 0.243333914714786, 0.06734508106390252, 0]\n",
      "The final train F1 score is 0.22809184351057366\n",
      "The final test F1 score is 0.19219376525542295\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [13:57<04:35, 137.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with 71 Estimators\n",
      "The Combined Average F1 scores of train Terminals  [0.24350802998342405, 0.18608352707711984, 0.19005693626217415, 0.19222597870137273, 0.1440699228836362, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.2010180242792677, 0.09949651186946541, 0.07504938757507348, 0.24707392482799231, 0.0672102015157659, 0]\n",
      "The final train F1 score is 0.21792430033673263\n",
      "The final test F1 score is 0.1831135341506861\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [17:37<02:42, 162.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with 81 Estimators\n",
      "The Combined Average F1 scores of train Terminals  [0.24468529721930762, 0.18763236246387663, 0.1912342034980578, 0.19340324593725644, 0.14536066115789315, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.2078886944460614, 0.09970379249586839, 0.07276612794350522, 0.24775376786514353, 0.06743888633275671, 0]\n",
      "The final train F1 score is 0.21913779664315927\n",
      "The final test F1 score is 0.18724322853862538\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [21:58<00:00, 131.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with 91 Estimators\n",
      "The Combined Average F1 scores of train Terminals  [0.25071800225982344, 0.1937600593139631, 0.19726690853857365, 0.19943595097777223, 0.1464494090843074, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.21099745682035886, 0.10013778732534631, 0.07663242566978201, 0.2506691287286949, 0.06726384835946479, 0]\n",
      "The final train F1 score is 0.22473057432767873\n",
      "The final test F1 score is 0.18987615394411292\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for estimator in tqdm(range(1,100, 10)):\n",
    "    f1_state_terminal=[0,0,0,0,0, 0] # order available, passive, charging, offline, down\n",
    "    f1_state_terminal_test=[0,0,0,0,0, 0] # order available, passive, charging, offline, down\n",
    "    label_count=[0,0,0,0,0,0]\n",
    "    for i in range(0,data.shape[1]):\n",
    "    \n",
    "        terminal= data.columns[i] # Extracting the column names from the dataframe\n",
    "    #num_class=data[terminal].unique() # Unique labels present in the dataframe column\n",
    "        weekend=data[terminal].apply(label_encoder)\n",
    "        num_class=weekend.unique()\n",
    "    \n",
    "        weekend_test=test_data[terminal].apply(label_encoder)\n",
    "        num_class_test=weekend_test.unique()\n",
    "        num_class_test.sort()\n",
    "        num_class.sort()\n",
    "        if len(num_class)>1:\n",
    "        \n",
    "            y=np.array(weekend).reshape(-1,1) # label encoding class labels\n",
    "            y_test=np.array(weekend_test).reshape(-1,1)\n",
    "        #print(y)\n",
    "        \n",
    "            clf = RandomForestClassifier(n_estimators=estimator, max_depth=2, min_samples_split=5, min_samples_leaf =5,\n",
    "                  class_weight= weight_func(num_class))  # Decision tree Classifier Initialization with default parameters # initializing logistics regression in multiclass setting\n",
    "            clf.fit(X_tr, y) # fitting our model\n",
    "        \n",
    "            y_pred=clf.predict(X_tr)\n",
    "            state_f1=f1_score(y, y_pred, average=None)\n",
    "        \n",
    "            y_pred_test=clf.predict(X_te)\n",
    "            state_f1_test=f1_score(y_test, y_pred_test, average=None)\n",
    "        \n",
    "            idx=0\n",
    "            for label in num_class:\n",
    "            #print(\"more than 1\",num_class)\n",
    "                f1_state_terminal[label]+=state_f1[idx]\n",
    "                label_count[label]+=1\n",
    "                idx+=1\n",
    "            #print('passed from if ')\n",
    "            \n",
    "                idx=0\n",
    "            for label in num_class_test:\n",
    "                f1_state_terminal_test[label]+=state_f1_test[idx]\n",
    "                idx+=1\n",
    "          \n",
    "        else:\n",
    "            for label in num_class:\n",
    "            #print('1 class',num_class)\n",
    "                f1_state_terminal[label]+=1 # Adding F1 score as 1 to the state where a terminal is in only one mode\n",
    "                label_count[label]+=1\n",
    "            #print('passed from else')\n",
    "        \n",
    "            for label in num_class_test:\n",
    "                f1_state_terminal_test[label]+=1 # Adding F1 score as 1 to the state where a terminal is in only one mode\n",
    "    \n",
    "    print(\"F1 score with {0} Estimators\".format(estimator))\n",
    "    printResults()\n",
    "    print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:49<07:28, 49.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with 1 Estimators\n",
      "The Combined Average F1 scores of train Terminals  [0.6723970845541192, 0.6070748627764291, 0.6211150332720681, 0.6211150332720681, 0.3409119457452279, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.4603928930051592, 0.077779524654902, 0.08383013456418921, 0.19434904027292785, 0.05764286269847443, 0]\n",
      "The final train F1 score is 0.6254261931347845\n",
      "The final test F1 score is 0.3262440745157952\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [07:10<19:51, 148.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with 11 Estimators\n",
      "The Combined Average F1 scores of train Terminals  [0.7919713516259398, 0.7222969902658359, 0.737039877964649, 0.7406893003438884, 0.41612964699510296, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.4747368674379774, 0.09426645502222103, 0.10690016302252707, 0.1985519240211642, 0.058235965693714704, 0]\n",
      "The final train F1 score is 0.7404793290512683\n",
      "The final test F1 score is 0.3381185617219402\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [18:58<36:56, 316.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with 21 Estimators\n",
      "The Combined Average F1 scores of train Terminals  [0.8090272432179173, 0.7387858275175836, 0.7540957695566266, 0.757745191935866, 0.42610382429556787, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.47918668850698376, 0.09985434684065043, 0.11999220565538937, 0.18878391804071729, 0.057954997104231416, 0]\n",
      "The final train F1 score is 0.7568559081310521\n",
      "The final test F1 score is 0.34008277842544743\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [36:20<53:26, 534.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with 31 Estimators\n",
      "The Combined Average F1 scores of train Terminals  [0.8182001663484233, 0.7477203729694656, 0.7632686926871326, 0.766918115066372, 0.43112498871289323, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.48386559646680705, 0.1008043900642737, 0.12330564267605046, 0.18484048207191692, 0.057954997104231416, 0]\n",
      "The final train F1 score is 0.7656371513658426\n",
      "The final test F1 score is 0.3424011884079616\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [1:00:50<1:07:54, 814.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with 41 Estimators\n",
      "The Combined Average F1 scores of train Terminals  [0.8253796768571933, 0.7547104190609194, 0.7704471116656102, 0.774097625575142, 0.4350711814626745, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.4878540673005034, 0.10465288203522696, 0.1242701858572577, 0.180675494779359, 0.0580404671897015, 0]\n",
      "The final train F1 score is 0.772511298374597\n",
      "The final test F1 score is 0.3443415460488491\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [1:31:47<1:15:09, 1127.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with 51 Estimators\n",
      "The Combined Average F1 scores of train Terminals  [0.8315442934795451, 0.7607539871911836, 0.7766080121959583, 0.7802622421974936, 0.43840267374841363, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.4906374841003231, 0.10665790499576155, 0.12553056421074493, 0.17959807211866488, 0.05855038956410794, 0]\n",
      "The final train F1 score is 0.7784113318147009\n",
      "The final test F1 score is 0.3460616760060976\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [2:10:13<1:14:04, 1481.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with 61 Estimators\n",
      "The Combined Average F1 scores of train Terminals  [0.8362060486986925, 0.7652907032919548, 0.7812697674151059, 0.7849239974166412, 0.44072409243658034, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.4911107068917684, 0.1104263655795212, 0.12546776356733932, 0.1838810310156446, 0.05882001358355309, 0]\n",
      "The final train F1 score is 0.7828529506169074\n",
      "The final test F1 score is 0.34742230147426945\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [2:53:34<1:00:34, 1817.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with 71 Estimators\n",
      "The Combined Average F1 scores of train Terminals  [0.840066714077566, 0.769001222085645, 0.7851304327939792, 0.7887846627955146, 0.44257656396843786, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.49470757774548085, 0.11115438383337232, 0.12210636648092624, 0.18218668047267414, 0.05883360527539607, 0]\n",
      "The final train F1 score is 0.7865217252925699\n",
      "The final test F1 score is 0.3491130732505817\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [3:43:50<36:16, 2176.86s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with 81 Estimators\n",
      "The Combined Average F1 scores of train Terminals  [0.8430183729552657, 0.771830702785836, 0.7880820916716791, 0.7917363216732144, 0.44414341369145927, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.49397368344123843, 0.11201002913688668, 0.12057652913263439, 0.19325740956257836, 0.058870802152703836, 0]\n",
      "The final train F1 score is 0.7893397569877518\n",
      "The final test F1 score is 0.3507025382411573\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [4:37:52<00:00, 1667.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score with 91 Estimators\n",
      "The Combined Average F1 scores of train Terminals  [0.8457873838915021, 0.774542446511191, 0.7908511026079156, 0.7945053326094509, 0.44548248131952917, 0]\n",
      "The Combined Average F1 scores of test Terminals  [0.49486868020331626, 0.11311449905898366, 0.11962248099703496, 0.18652737761575539, 0.058856981001629685, 0]\n",
      "The final train F1 score is 0.7919756024499423\n",
      "The final test F1 score is 0.3500099669738038\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for estimator in tqdm(range(1,100, 10)):\n",
    "    f1_state_terminal=[0,0,0,0,0, 0] # order available, passive, charging, offline, down\n",
    "    f1_state_terminal_test=[0,0,0,0,0, 0] # order available, passive, charging, offline, down\n",
    "    label_count=[0,0,0,0,0,0]\n",
    "    for i in range(0,data.shape[1]):\n",
    "    \n",
    "        terminal= data.columns[i] # Extracting the column names from the dataframe\n",
    "    #num_class=data[terminal].unique() # Unique labels present in the dataframe column\n",
    "        weekend=data[terminal].apply(label_encoder)\n",
    "        num_class=weekend.unique()\n",
    "    \n",
    "        weekend_test=test_data[terminal].apply(label_encoder)\n",
    "        num_class_test=weekend_test.unique()\n",
    "        if len(num_class)>1:\n",
    "        \n",
    "            y=np.array(weekend).reshape(-1,1) # label encoding class labels\n",
    "            y_test=np.array(weekend_test).reshape(-1,1)\n",
    "        #print(y)\n",
    "        \n",
    "            clf = GradientBoostingClassifier(n_estimators=estimator, max_depth=3, min_samples_split=10, min_samples_leaf =10)  # Decision tree Classifier Initialization with default parameters # initializing logistics regression in multiclass setting\n",
    "            clf.fit(X_tr, y) # fitting our model\n",
    "        \n",
    "            y_pred=clf.predict(X_tr)\n",
    "            state_f1=f1_score(y, y_pred, average=None)\n",
    "        \n",
    "            y_pred_test=clf.predict(X_te)\n",
    "            state_f1_test=f1_score(y_test, y_pred_test, average=None)\n",
    "        \n",
    "            idx=0\n",
    "            for label in num_class:\n",
    "            #print(\"more than 1\",num_class)\n",
    "                f1_state_terminal[label]+=state_f1[idx]\n",
    "                label_count[label]+=1\n",
    "                idx+=1\n",
    "            #print('passed from if ')\n",
    "            \n",
    "                idx=0\n",
    "            for label in num_class_test:\n",
    "                f1_state_terminal_test[label]+=state_f1_test[idx]\n",
    "                idx+=1\n",
    "          \n",
    "        else:\n",
    "            for label in num_class:\n",
    "            #print('1 class',num_class)\n",
    "                f1_state_terminal[label]+=1 # Adding F1 score as 1 to the state where a terminal is in only one mode\n",
    "                label_count[label]+=1\n",
    "            #print('passed from else')\n",
    "        \n",
    "            for label in num_class_test:\n",
    "                f1_state_terminal_test[label]+=1 # Adding F1 score as 1 to the state where a terminal is in only one mode\n",
    "    \n",
    "    print(\"F1 score with {0} Estimators\".format(estimator))\n",
    "    printResults()\n",
    "    print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other work(Not to evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 10/273 [28:23<12:26:53, 170.39s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f1_state_terminal=[0,0,0,0,0, 0] # order available, passive, charging, offline, down\n",
    "f1_state_terminal_test=[0,0,0,0,0, 0] # order available, passive, charging, offline, down\n",
    "label_count=[0,0,0,0,0,0]\n",
    "for i in tqdm(range(0,data.shape[1])):\n",
    "    \n",
    "    terminal= data.columns[i] # Extracting the column names from the dataframe\n",
    "    #num_class=data[terminal].unique() # Unique labels present in the dataframe column\n",
    "    weekend=data[terminal].apply(label_encoder)\n",
    "    num_class=weekend.unique()\n",
    "    \n",
    "    weekend_test=test_data[terminal].apply(label_encoder)\n",
    "    num_class_test=weekend_test.unique()\n",
    "    if len(num_class)>1:\n",
    "        \n",
    "        y=np.array(weekend).reshape(-1,1) # label encoding class labels\n",
    "        y_test=np.array(weekend_test).reshape(-1,1)\n",
    "        #print(y)\n",
    "        \n",
    "        clf = KNeighborsClassifier() # Decision tree Classifier Initialization with default parameters # initializing logistics regression in multiclass setting\n",
    "        clf.fit(X_tr, y) # fitting our model\n",
    "        \n",
    "        y_pred=clf.predict(X_tr)\n",
    "        state_f1=f1_score(y, y_pred, average=None)\n",
    "        \n",
    "        y_pred_test=clf.predict(X_te)\n",
    "        state_f1_test=f1_score(y_test, y_pred_test, average=None)\n",
    "        \n",
    "        idx=0\n",
    "        for label in num_class:\n",
    "            #print(\"more than 1\",num_class)\n",
    "            f1_state_terminal[label]+=state_f1[idx]\n",
    "            label_count[label]+=1\n",
    "            idx+=1\n",
    "            #print('passed from if ')\n",
    "            \n",
    "            idx=0\n",
    "        for label in num_class_test:\n",
    "            #print(\"more than 1\",num_class)\n",
    "            f1_state_terminal_test[label]+=state_f1_test[idx]\n",
    "            #label_count[label]+=1\n",
    "            idx+=1\n",
    "            #print('passed from if ')\n",
    "    else:\n",
    "        for label in num_class:\n",
    "            #print('1 class',num_class)\n",
    "            f1_state_terminal[label]+=1 # Adding F1 score as 1 to the state where a terminal is in only one mode\n",
    "            label_count[label]+=1\n",
    "            #print('passed from else')\n",
    "        \n",
    "        for label in num_class_test:\n",
    "            #print('1 class',num_class)\n",
    "            f1_state_terminal_test[label]+=1 # Adding F1 score as 1 to the state where a terminal is in only one mode\n",
    "            #label_count_test[label]+=1\n",
    "            #print('passed from else')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/273 [15:47<35:33:06, 472.28s/it]"
     ]
    }
   ],
   "source": [
    "f1_state_terminal=[0,0,0,0,0, 0] # order available, passive, charging, offline, down\n",
    "for i in tqdm(range(0,data.shape[1])):\n",
    "    \n",
    "    terminal= data.columns[i] # Extracting the column names from the dataframe\n",
    "    #num_class=data[terminal].unique() # Unique labels present in the dataframe column\n",
    "    weekend=data[terminal].apply(label_encoder)\n",
    "    num_class=weekend.unique()\n",
    "    if len(num_class)>1:\n",
    "        \n",
    "        y=np.array(weekend).reshape(-1,1) # label encoding class labels \n",
    "        #print(y)\n",
    "        \n",
    "        knn_clf = KNeighborsClassifier()  # Decision tree Classifier Initialization with default parameters # initializing logistics regression in multiclass setting\n",
    "        \n",
    "        n_neighbors = range(1, 21, 2)\n",
    "        weights = ['uniform', 'distance']\n",
    "        metric = ['euclidean', 'manhattan', 'minkowski']\n",
    "        # define grid search\n",
    "        grid = dict(n_neighbors=n_neighbors,weights=weights,metric=metric)\n",
    "        cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "        clf= GridSearchCV(estimator=knn_clf, param_grid=grid, n_jobs=-1, cv=cv, scoring='roc_auc',error_score=0)\n",
    "        clf.fit(X_tr, y) # fitting our model\n",
    "        \n",
    "        best= clf.best_estimator_\n",
    "        \n",
    "        best.fit(X_tr, y) # fitting our model\n",
    "        y_pred=best.predict(X_tr)\n",
    "        state_f1=f1_score(y, y_pred, average=None)\n",
    "        idx=0\n",
    "        for label in num_class:\n",
    "            #print(\"more than 1\",num_class)\n",
    "            f1_state_terminal[label]+=state_f1[idx]\n",
    "            idx+=1\n",
    "            #print('passed from if ')\n",
    "    else:\n",
    "        for label in num_class:\n",
    "            #print('1 class',num_class)\n",
    "            f1_state_terminal[label]+=0 # Adding F1 score as 1 to the state where a terminal is in only one mode\n",
    "            #print('passed from else')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HyperParam(X_tr,X_te y, tree_depth, num_class, num_class_test):\n",
    "    lst_train=[] \n",
    "    lst_test=[]\n",
    "    for i in range(1, tree_depth):\n",
    "        clf = DecisionTreeClassifier(max_depth=depth, min_samples_split=10, min_samples_leaf =10,class_weight= weight_func(num_class))  # Decision tree Classifier Initialization with default parameters # initializing logistics regression in multiclass setting\n",
    "        clf.fit(X_tr, y) # fitting our model\n",
    "        \n",
    "        y_pred=clf.predict(X_tr)\n",
    "        state_f1=f1_score(y, y_pred, average=None)\n",
    "        \n",
    "        y_pred_test=clf.predict(X_te)\n",
    "        state_f1_test=f1_score(y_test, y_pred_test, average=None)\n",
    "        \n",
    "        idx=0\n",
    "        for label in num_class:\n",
    "            #print(\"more than 1\",num_class)\n",
    "            f1_state_terminal[label]+=state_f1[idx]\n",
    "            label_count[label]+=1\n",
    "            idx+=1\n",
    "            #print('passed from if ')\n",
    "            \n",
    "        idx=0\n",
    "        for label in num_class_test:\n",
    "            f1_state_terminal_test[label]+=state_f1_test[idx]\n",
    "            idx+=1\n",
    "        lst_train.apeend(np.sum(f1_state_terminal))\n",
    "        lst_test.append(np.sum(f1_state_terminal_test))\n",
    "    return  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 1) (60,) (20, 1) (20,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sktime.datasets import load_arrow_head\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sktime.datasets import load_basic_motions\n",
    "\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "\n",
    "\n",
    "\n",
    "X, y = load_basic_motions(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.iloc[:, [0]], y)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "knn = KNeighborsTimeSeriesClassifier(n_neighbors=2, distance=\"dtw\")\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data= pd.read_csv('ytrain_NpxebDC.csv', parse_dates=['timestamp']) # Reading the csv file in data dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=Data['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2019-11-25 00:00:00+00:00\n",
      "1       2019-11-25 00:15:00+00:00\n",
      "2       2019-11-25 00:30:00+00:00\n",
      "3       2019-11-25 00:45:00+00:00\n",
      "4       2019-11-25 01:00:00+00:00\n",
      "                   ...           \n",
      "31227   2020-11-08 22:45:00+00:00\n",
      "31228   2020-11-08 23:00:00+00:00\n",
      "31229   2020-11-08 23:15:00+00:00\n",
      "31230   2020-11-08 23:30:00+00:00\n",
      "31231   2020-11-08 23:45:00+00:00\n",
      "Name: timestamp, Length: 31232, dtype: datetime64[ns, UTC]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekend=data['S19-T1'].apply(label_encoder)\n",
    "#num=weekend.unique()\n",
    "\n",
    "y=np.array(weekend).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_nested is a nested DataFrame: True\n",
      "The cell contains a <class 'pandas.core.series.Series'>.\n",
      "The nested DataFrame has shape (31232, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0     11\n",
       "1     25\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0     11\n",
       "1     25\n",
       "2      0\n",
       "3     15\n",
       "4      0\n",
       "5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0     11\n",
       "1     25\n",
       "2      0\n",
       "3     30\n",
       "4      0\n",
       "5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0     11\n",
       "1     25\n",
       "2      0\n",
       "3     45\n",
       "4      0\n",
       "5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0     11\n",
       "1     25\n",
       "2      1\n",
       "3      0\n",
       "4      0\n",
       "5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  0     11\n",
       "1     25\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "5...\n",
       "1  0     11\n",
       "1     25\n",
       "2      0\n",
       "3     15\n",
       "4      0\n",
       "5...\n",
       "2  0     11\n",
       "1     25\n",
       "2      0\n",
       "3     30\n",
       "4      0\n",
       "5...\n",
       "3  0     11\n",
       "1     25\n",
       "2      0\n",
       "3     45\n",
       "4      0\n",
       "5...\n",
       "4  0     11\n",
       "1     25\n",
       "2      1\n",
       "3      0\n",
       "4      0\n",
       "5..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sktime.utils.data_processing import (\n",
    "    from_2d_array_to_nested,\n",
    "    from_nested_to_2d_array,\n",
    "    is_nested_dataframe,\n",
    ")\n",
    "\n",
    "X_nested = from_2d_array_to_nested(X_tr)\n",
    "print(f\"X_nested is a nested DataFrame: {is_nested_dataframe(X_nested)}\")\n",
    "print(f\"The cell contains a {type(X_nested.iloc[0,0])}.\")\n",
    "print(f\"The nested DataFrame has shape {X_nested.shape}\")\n",
    "X_nested.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_nested, y)\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsTimeSeriesClassifier(n_neighbors=2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsTimeSeriesClassifier(n_neighbors=2, distance=\"dtw\")\n",
    "knn.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Buffer dtype mismatch, expected 'double' but got 'long long'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-5c888e60d86d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    498\u001b[0m         \"\"\"\n\u001b[0;32m    499\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sktime\\classification\\distance_based\\_time_series_neighbors.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[0mcheck_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__code__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_array_ts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__code__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sktime\\classification\\distance_based\\_time_series_neighbors.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneigh_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1621\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1622\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1623\u001b[1;33m         D_chunk = pairwise_distances(X_chunk, Y, metric=metric,\n\u001b[0m\u001b[0;32m   1624\u001b[0m                                      n_jobs=n_jobs, **kwds)\n\u001b[0;32m   1625\u001b[0m         if ((X is Y or Y is None)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1788\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1790\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m     \u001b[1;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_pairwise_callable\u001b[1;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1401\u001b[0m         \u001b[0miterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1402\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1403\u001b[1;33m             \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1405\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msktime\\distances\\elastic_cython.pyx\u001b[0m in \u001b[0;36msktime.distances.elastic_cython.dtw_distance\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Buffer dtype mismatch, expected 'double' but got 'long long'"
     ]
    }
   ],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
