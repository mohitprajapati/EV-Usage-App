{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP+LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDHWXnNTE7Lh"
      },
      "source": [
        "import numpy as np # Importing numpy for performing array and matrix operations \n",
        "import pandas as pd # Importing pandas to read data in dataframe\n",
        "\n",
        "# Libraries to plot the distribution of classes \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime #I will use this to Convert ISO8601 format to unix time\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "\n",
        "import time #I will use this to Convert ISO8601 format to unix time\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn import linear_model  #Importing linear models like logistics regression and SVC\n",
        "from sklearn.preprocessing import LabelEncoder  # To convert every class  into numeric labels \n",
        "from sklearn.metrics import f1_score       # to calculate F1 score \n",
        "from sklearn.metrics import classification_report # to know every metric\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcwHmvCWFoNQ",
        "outputId": "77d2fbac-759e-401e-da28-c584c851b2cc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwctcRbqE7Lm"
      },
      "source": [
        "data1= pd.read_csv('/content/drive/MyDrive/AAIC_Assignment/ytrain_NpxebDC.csv', parse_dates=['timestamp'],\n",
        "index_col= ['timestamp']) # Reading the csv file in data dataframe "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiliKCC2QJ3I"
      },
      "source": [
        "data, test_data=train_test_split(data1, test_size=0.10, shuffle=False)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "yEBJEDtPE7Ln",
        "outputId": "b98442e1-27ab-4fd8-d618-e4ceb03e5a4e"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S7-T1</th>\n",
              "      <th>S2-T1</th>\n",
              "      <th>S19-T1</th>\n",
              "      <th>S56-T3</th>\n",
              "      <th>S85-T3</th>\n",
              "      <th>S16-T3</th>\n",
              "      <th>S16-T1</th>\n",
              "      <th>S94-T3</th>\n",
              "      <th>S28-T1</th>\n",
              "      <th>S62-T3</th>\n",
              "      <th>S14-T3</th>\n",
              "      <th>S8-T1</th>\n",
              "      <th>S8-T3</th>\n",
              "      <th>S34-T3</th>\n",
              "      <th>S6-T2</th>\n",
              "      <th>S29-T3</th>\n",
              "      <th>S64-T1</th>\n",
              "      <th>S11-T1</th>\n",
              "      <th>S76-T3</th>\n",
              "      <th>S59-T1</th>\n",
              "      <th>S58-T1</th>\n",
              "      <th>S58-T3</th>\n",
              "      <th>S21-T3</th>\n",
              "      <th>S96-T3</th>\n",
              "      <th>S30-T1</th>\n",
              "      <th>S77-T1</th>\n",
              "      <th>S35-T3</th>\n",
              "      <th>S71-T3</th>\n",
              "      <th>S89-T1</th>\n",
              "      <th>S51-T3</th>\n",
              "      <th>S51-T1</th>\n",
              "      <th>S38-T3</th>\n",
              "      <th>S79-T1</th>\n",
              "      <th>S79-T3</th>\n",
              "      <th>S33-T3</th>\n",
              "      <th>S33-T1</th>\n",
              "      <th>S50-T3</th>\n",
              "      <th>S1-T3</th>\n",
              "      <th>S49-T1</th>\n",
              "      <th>S60-T3</th>\n",
              "      <th>...</th>\n",
              "      <th>S71-T2</th>\n",
              "      <th>S36-T2</th>\n",
              "      <th>S79-T2</th>\n",
              "      <th>S16-T2</th>\n",
              "      <th>S94-T2</th>\n",
              "      <th>S9-T2</th>\n",
              "      <th>S21-T1</th>\n",
              "      <th>S92-T2</th>\n",
              "      <th>S11-T2</th>\n",
              "      <th>S51-T2</th>\n",
              "      <th>S60-T2</th>\n",
              "      <th>S19-T2</th>\n",
              "      <th>S62-T2</th>\n",
              "      <th>S31-T2</th>\n",
              "      <th>S96-T2</th>\n",
              "      <th>S27-T2</th>\n",
              "      <th>S23-T2</th>\n",
              "      <th>S28-T2</th>\n",
              "      <th>S37-T2</th>\n",
              "      <th>S39-T2</th>\n",
              "      <th>S68-T2</th>\n",
              "      <th>S56-T2</th>\n",
              "      <th>S41-T2</th>\n",
              "      <th>S35-T2</th>\n",
              "      <th>S7-T2</th>\n",
              "      <th>S75-T2</th>\n",
              "      <th>S20-T2</th>\n",
              "      <th>S95-T2</th>\n",
              "      <th>S5-T2</th>\n",
              "      <th>S2-T2</th>\n",
              "      <th>S47-T2</th>\n",
              "      <th>S65-T2</th>\n",
              "      <th>S32-T2</th>\n",
              "      <th>S21-T2</th>\n",
              "      <th>S13-T2</th>\n",
              "      <th>S97-T2</th>\n",
              "      <th>S25-T1</th>\n",
              "      <th>S25-T2</th>\n",
              "      <th>S98-T2</th>\n",
              "      <th>S99-T2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-11-25 00:00:00+00:00</th>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>...</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-11-25 00:15:00+00:00</th>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>...</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-11-25 00:30:00+00:00</th>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>...</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-11-25 00:45:00+00:00</th>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>...</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-11-25 01:00:00+00:00</th>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>...</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 273 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          S7-T1 S2-T1     S19-T1  ... S25-T2 S98-T2 S99-T2\n",
              "timestamp                                         ...                     \n",
              "2019-11-25 00:00:00+00:00  Down  Down  Available  ...    NaN    NaN    NaN\n",
              "2019-11-25 00:15:00+00:00  Down  Down  Available  ...    NaN    NaN    NaN\n",
              "2019-11-25 00:30:00+00:00  Down  Down  Available  ...    NaN    NaN    NaN\n",
              "2019-11-25 00:45:00+00:00  Down  Down  Available  ...    NaN    NaN    NaN\n",
              "2019-11-25 01:00:00+00:00  Down  Down  Available  ...    NaN    NaN    NaN\n",
              "\n",
              "[5 rows x 273 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "zi7ZmzVOQQAy",
        "outputId": "14f22540-b555-4fad-e732-1cabcad53f04"
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S7-T1</th>\n",
              "      <th>S2-T1</th>\n",
              "      <th>S19-T1</th>\n",
              "      <th>S56-T3</th>\n",
              "      <th>S85-T3</th>\n",
              "      <th>S16-T3</th>\n",
              "      <th>S16-T1</th>\n",
              "      <th>S94-T3</th>\n",
              "      <th>S28-T1</th>\n",
              "      <th>S62-T3</th>\n",
              "      <th>S14-T3</th>\n",
              "      <th>S8-T1</th>\n",
              "      <th>S8-T3</th>\n",
              "      <th>S34-T3</th>\n",
              "      <th>S6-T2</th>\n",
              "      <th>S29-T3</th>\n",
              "      <th>S64-T1</th>\n",
              "      <th>S11-T1</th>\n",
              "      <th>S76-T3</th>\n",
              "      <th>S59-T1</th>\n",
              "      <th>S58-T1</th>\n",
              "      <th>S58-T3</th>\n",
              "      <th>S21-T3</th>\n",
              "      <th>S96-T3</th>\n",
              "      <th>S30-T1</th>\n",
              "      <th>S77-T1</th>\n",
              "      <th>S35-T3</th>\n",
              "      <th>S71-T3</th>\n",
              "      <th>S89-T1</th>\n",
              "      <th>S51-T3</th>\n",
              "      <th>S51-T1</th>\n",
              "      <th>S38-T3</th>\n",
              "      <th>S79-T1</th>\n",
              "      <th>S79-T3</th>\n",
              "      <th>S33-T3</th>\n",
              "      <th>S33-T1</th>\n",
              "      <th>S50-T3</th>\n",
              "      <th>S1-T3</th>\n",
              "      <th>S49-T1</th>\n",
              "      <th>S60-T3</th>\n",
              "      <th>...</th>\n",
              "      <th>S71-T2</th>\n",
              "      <th>S36-T2</th>\n",
              "      <th>S79-T2</th>\n",
              "      <th>S16-T2</th>\n",
              "      <th>S94-T2</th>\n",
              "      <th>S9-T2</th>\n",
              "      <th>S21-T1</th>\n",
              "      <th>S92-T2</th>\n",
              "      <th>S11-T2</th>\n",
              "      <th>S51-T2</th>\n",
              "      <th>S60-T2</th>\n",
              "      <th>S19-T2</th>\n",
              "      <th>S62-T2</th>\n",
              "      <th>S31-T2</th>\n",
              "      <th>S96-T2</th>\n",
              "      <th>S27-T2</th>\n",
              "      <th>S23-T2</th>\n",
              "      <th>S28-T2</th>\n",
              "      <th>S37-T2</th>\n",
              "      <th>S39-T2</th>\n",
              "      <th>S68-T2</th>\n",
              "      <th>S56-T2</th>\n",
              "      <th>S41-T2</th>\n",
              "      <th>S35-T2</th>\n",
              "      <th>S7-T2</th>\n",
              "      <th>S75-T2</th>\n",
              "      <th>S20-T2</th>\n",
              "      <th>S95-T2</th>\n",
              "      <th>S5-T2</th>\n",
              "      <th>S2-T2</th>\n",
              "      <th>S47-T2</th>\n",
              "      <th>S65-T2</th>\n",
              "      <th>S32-T2</th>\n",
              "      <th>S21-T2</th>\n",
              "      <th>S13-T2</th>\n",
              "      <th>S97-T2</th>\n",
              "      <th>S25-T1</th>\n",
              "      <th>S25-T2</th>\n",
              "      <th>S98-T2</th>\n",
              "      <th>S99-T2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-10-02 04:45:00+00:00</th>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Available</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>...</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Down</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-02 05:00:00+00:00</th>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Available</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>...</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Down</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-02 05:15:00+00:00</th>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Available</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>...</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Down</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-02 05:30:00+00:00</th>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Available</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>...</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Down</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-02 05:45:00+00:00</th>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Available</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Down</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Charging</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>...</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Down</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Down</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Passive</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Offline</td>\n",
              "      <td>Available</td>\n",
              "      <td>Available</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 273 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          S7-T1    S2-T1  ...     S98-T2     S99-T2\n",
              "timestamp                                 ...                      \n",
              "2020-10-02 04:45:00+00:00  Down  Offline  ...  Available  Available\n",
              "2020-10-02 05:00:00+00:00  Down  Offline  ...  Available  Available\n",
              "2020-10-02 05:15:00+00:00  Down  Offline  ...  Available  Available\n",
              "2020-10-02 05:30:00+00:00  Down  Offline  ...  Available  Available\n",
              "2020-10-02 05:45:00+00:00  Down  Offline  ...  Available  Available\n",
              "\n",
              "[5 rows x 273 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tRM2x4rE7Lo",
        "outputId": "89bae56a-9a21-4575-e573-ee0df256d554"
      },
      "source": [
        "for col in data:    # for every column in the data frame\n",
        "    if col!='timestamp':\n",
        "        data[col]=data[col].fillna('Offline')  # Filling the missing class label with Down as explained above\n",
        "data['S7-T1'].isnull().sum() # counting the NAN values"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRyVT82IE7Lp"
      },
      "source": [
        "def date_time(data):\n",
        "# Initializing Empty lists\n",
        "   \n",
        "    month=[]\n",
        "    week=[]\n",
        "    date=[]\n",
        "    hr=[]\n",
        "    minute=[]\n",
        "\n",
        "# I have made timestamp column as an index of the dataframe for easy plotting operations\n",
        "    for i in data.index: # For every index of the dataframe\n",
        "    #print(i)\n",
        "    #break\n",
        "    #dt = datetime.datetime.strptime(i, \"%Y-%m-%dT%H:%M:%S%z\")\n",
        "        dt=i\n",
        "    # Appending the month, day, weekday, hour and minute in lists\n",
        "        \n",
        "        month.append(dt.month)\n",
        "        week.append(dt.weekday()) #Monday is 0 and Sunday is 6\n",
        "        date.append(dt.day)\n",
        "        hr.append(dt.hour)\n",
        "        minute.append(dt.minute)\n",
        "# making X as a data frame \n",
        "    return pd.DataFrame(list(zip( month, week, date, hr, minute)), columns =['Month_name', 'Week_number', 'Date', 'Hour', 'Minute'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ZQtyvKvqE7Lp",
        "outputId": "0115434c-f233-4dc6-a41d-bbe8aa9105ed"
      },
      "source": [
        "X=date_time(data)\n",
        "X.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Month_name</th>\n",
              "      <th>Week_number</th>\n",
              "      <th>Date</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Minute</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Month_name  Week_number  Date  Hour  Minute\n",
              "0          11            0    25     0       0\n",
              "1          11            0    25     0      15\n",
              "2          11            0    25     0      30\n",
              "3          11            0    25     0      45\n",
              "4          11            0    25     1       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "etdG_EEcQePx",
        "outputId": "7e76c3de-b41a-4664-894e-da4c3a565910"
      },
      "source": [
        "X_test=date_time(test_data)\n",
        "X_test.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Month_name</th>\n",
              "      <th>Week_number</th>\n",
              "      <th>Date</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Minute</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Month_name  Week_number  Date  Hour  Minute\n",
              "0          10            4     2     4      45\n",
              "1          10            4     2     5       0\n",
              "2          10            4     2     5      15\n",
              "3          10            4     2     5      30\n",
              "4          10            4     2     5      45"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXa6RyCCE7Lq"
      },
      "source": [
        "# daypart function\n",
        "def DayPart(hour):\n",
        "    if hour in [2,3,4,5]: # dawn ==1\n",
        "        return 1\n",
        "    elif hour in [6,7,8,9]: # morning ==2\n",
        "        return 2\n",
        "    elif hour in [10,11,12,13]: #  noon==3\n",
        "        return 3\n",
        "    elif hour in [14,15,16,17]: # Afternoon==4\n",
        "        return 4\n",
        "    elif hour in [18,19,20,21]:  # evening ==5\n",
        "        return 5\n",
        "    else: return 6    # midnight==6\n",
        "# utilize it along with apply method\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN5Q0dcNE7Lr",
        "outputId": "2ae0986b-7407-4c7e-808a-645790617915"
      },
      "source": [
        "dayparts = X['Hour'].apply(DayPart)\n",
        "dayparts_test=X_test['Hour'].apply(DayPart)\n",
        "print(dayparts.shape)\n",
        "print(dayparts_test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28108,)\n",
            "(3124,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbrP7ECiQmXI",
        "outputId": "c266b84b-583d-4c8c-b8f6-26a751bc2549"
      },
      "source": [
        "# one hot encoding\n",
        "daypart_ohe= pd.get_dummies(dayparts)\n",
        "daypart_test_ohe=pd.get_dummies(dayparts_test)\n",
        "print(daypart_ohe.shape)\n",
        "print(daypart_test_ohe.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28108, 6)\n",
            "(3124, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtgZjXJME7Ls",
        "outputId": "0c323303-0797-49e6-8a8b-2bbe22714901"
      },
      "source": [
        "# one hot encoding\n",
        "week_number_ohe= pd.get_dummies(X['Week_number'])\n",
        "week_number_test_ohe=pd.get_dummies(X_test['Week_number'])\n",
        "print(week_number_ohe.shape)\n",
        "print(week_number_test_ohe.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28108, 7)\n",
            "(3124, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc9hkqUME7Ls"
      },
      "source": [
        "# daypart function\n",
        "def IsWeekEnd(number):\n",
        "    if number in [5,6]: # if staurday or sunday return 1\n",
        "        return 1\n",
        "    else: return 0    # weekdays=6"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4VYxjRyQukE",
        "outputId": "1f744137-ac8e-4aba-ad2c-966ab2d4a2ca"
      },
      "source": [
        "weekend=X['Week_number'].apply(IsWeekEnd)\n",
        "weekend_test=X_test['Week_number'].apply(IsWeekEnd)\n",
        "print(weekend.shape)\n",
        "print(weekend_test.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28108,)\n",
            "(3124,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yYrLoJSQxD6"
      },
      "source": [
        "x=X.drop(['Week_number'], axis=1)\n",
        "x_test=X_test.drop(['Week_number'], axis=1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amzrI85DQzSe",
        "outputId": "6494d198-79a9-442e-9945-9340f8665f36"
      },
      "source": [
        "# merge two sparse matrices: https://stackoverflow.com/a/19710648/4084039 \n",
        "X_tr = pd.concat([x,daypart_ohe, week_number_ohe, weekend], axis = 1)\n",
        "X_tr.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28108, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB9gLaqtQ3cW",
        "outputId": "44e8584c-9784-4ce9-d59e-a3398554424f"
      },
      "source": [
        "X_te=pd.concat([x_test,daypart_test_ohe, week_number_test_ohe, weekend_test], axis = 1)\n",
        "X_te.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3124, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwDkfDiDE7Lu"
      },
      "source": [
        "### Random Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTX8IBU0E7Lv"
      },
      "source": [
        "\n",
        "def label_encoder(column):\n",
        "    '''\n",
        "    This function help us to Encode the class labels of \n",
        "    the corresponding terminal into their respective \n",
        "    numeric labels\n",
        "    '''\n",
        "    if column =='Available': # Available ==0\n",
        "        return 0\n",
        "    elif column=='Charging': # charging==1\n",
        "        return 1\n",
        "    elif column=='Passive': # Passive==2\n",
        "        return 2\n",
        "    elif column=='Offline': # offline==3\n",
        "        return 3\n",
        "    else: return 4    # Down==4\n",
        "# utilize it along with apply method"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmPN3WigE7Lv"
      },
      "source": [
        "def weight_func(num_class):\n",
        "    dct={}\n",
        "    for num in num_class:\n",
        "        #if num==0:  # Available\n",
        "           # dct[0]=1\n",
        "        if num==1:    #Charging\n",
        "            dct[1]=9\n",
        "        if num==2:    # Passive\n",
        "            dct[2]=10\n",
        "        if num==3:     # Offline\n",
        "            dct[3]=3\n",
        "        if num==4:     # down\n",
        "            dct[4]=5\n",
        "    return dct"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbkR5bCBRKs9",
        "outputId": "d393bf0a-d01d-46a9-d4bc-8b08f6261cca"
      },
      "source": [
        "\n",
        "av_count=0\n",
        "ch_count=0\n",
        "pa_count=0\n",
        "do_count=0\n",
        "of_count=0\n",
        "for i in tqdm(range(0,data.shape[1])):\n",
        "    \n",
        "    terminal= data.columns[i] # Extracting the column names from the dataframe\n",
        "    labels=data[terminal]\n",
        "    for i in labels:\n",
        "        #print(i)\n",
        "        if i=='Available':\n",
        "            av_count+=1\n",
        "        if i=='Charging':\n",
        "            ch_count+=1\n",
        "        if i=='Passive':\n",
        "            pa_count+=1\n",
        "        if i=='Down':\n",
        "            do_count+=1\n",
        "        if i=='Offline':\n",
        "            of_count+=1\n",
        "tot_count=av_count+ch_count+pa_count+do_count+of_count\n",
        "print(tot_count)\n",
        "prob_list=[0,0,0,0,0]# order available, passive, charging, offline, down\n",
        "prob_list[0]=av_count/tot_count\n",
        "prob_list[1]=pa_count/tot_count\n",
        "prob_list[2]=ch_count/tot_count\n",
        "prob_list[3]=of_count/tot_count\n",
        "prob_list[4]=do_count/tot_count"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 273/273 [00:02<00:00, 104.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7673484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuEmY2BoloK9"
      },
      "source": [
        "Multi layer Perceptron model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEN7g8BjORpv"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import Adagrad\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.utils import class_weight \n",
        "from keras.layers import Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from numpy import array"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMPAsK1piAzF"
      },
      "source": [
        "class_weight = {0: 1.,\n",
        "                1: 9.,\n",
        "               2: 10.,\n",
        "               3:3.,\n",
        "               4:5}"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EajLYLei8hBz",
        "outputId": "5aa51a77-9cad-4a57-ccd7-1ad66c61e5f3"
      },
      "source": [
        "\n",
        "f1_state_terminal=[0,0,0,0,0, 0] # order available, passive, charging, offline, down\n",
        "f1_state_terminal_test=[0,0,0,0,0, 0] # order available, passive, charging, offline, down\n",
        "label_count=[0,0,0,0,0,0]\n",
        "for i in tqdm(range(0,data.shape[1])):\n",
        "  tf.keras.backend.clear_session()\n",
        "  terminal= data.columns[i] # Extracting the column names from the dataframe\n",
        "    #num_class=data[terminal].unique() # Unique labels present in the dataframe column\n",
        "  weekend=data[terminal].apply(label_encoder)\n",
        "  num_class=weekend.unique()\n",
        "  num_class.sort()\n",
        "  weekend_test=test_data[terminal].apply(label_encoder)\n",
        "  num_class_test=weekend_test.unique()\n",
        "  num_class_test.sort()\n",
        "  if len(num_class)>1:\n",
        "    unit=len(num_class)\n",
        "    #print(unit)\n",
        "    y=np.array(weekend).reshape(-1,1) # label encoding class labels\n",
        "    y_test=np.array(weekend_test).reshape(-1,1)\n",
        "    y_train1 = to_categorical(y, 5)\n",
        "    y_test1 = to_categorical(y_test, 5)\n",
        "    #print(y_train1.shape)\n",
        "    #print(y_test1.shape)   \n",
        "            # define model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(1024, activation='relu', input_dim=X_tr.shape[1]))\n",
        "    model.add(Dense(512))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(128))\n",
        "    model.add(Dense(units=5, activation='softmax'))\n",
        "    adam = Adam()\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "    \n",
        "    #class_weights = class_weight.compute_class_weight('balanced',weekend.unique(y) ,data[terminal])\n",
        "    #class_weights = dict(enumerate(class_weights))\n",
        "    model.fit(X_tr, y_train1, epochs=20, batch_size=200, verbose=0, class_weight=class_weight)\n",
        "        \n",
        "    y_pred=model.predict(X_tr)\n",
        "    val_predict=np.argmax(y_pred, axis=1) \n",
        "    val_target=np.argmax(y_train1, axis=1) \n",
        "    state_f1=f1_score(val_target, val_predict, average=None)\n",
        "        \n",
        "    y_pred_test=model.predict(X_te)\n",
        "    val_predict=np.argmax(y_pred_test, axis=1) \n",
        "    val_target=np.argmax(y_test1, axis=1) \n",
        "    state_f1_test=f1_score(val_target, val_predict, average=None)\n",
        "        \n",
        "    idx=0\n",
        "    for label in num_class:\n",
        "            #print(\"more than 1\",num_class)\n",
        "        f1_state_terminal[label]+=state_f1[idx]\n",
        "        label_count[label]+=1\n",
        "        idx+=1\n",
        "            #print('passed from if ')\n",
        "            \n",
        "    idx=0\n",
        "    for label in num_class_test:\n",
        "        f1_state_terminal_test[label]+=state_f1_test[idx]\n",
        "        idx+=1\n",
        "          \n",
        "  else:\n",
        "    for label in num_class:\n",
        "            #print('1 class',num_class)\n",
        "        f1_state_terminal[label]+=1 # Adding F1 score as 1 to the state where a terminal is in only one mode\n",
        "        label_count[label]+=1\n",
        "            #print('passed from else')\n",
        "        \n",
        "    for label in num_class_test:\n",
        "        f1_state_terminal_test[label]+=1 # Adding F1 score as 1 to the state where a terminal is in only one mode\n",
        "    \n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 273/273 [40:30<00:00,  8.90s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wkshx6Q0RtlM",
        "outputId": "f2bc75ce-11f0-4675-f428-e09684e289d2"
      },
      "source": [
        "#print('The counts of the class labels in train data', label_count)\n",
        "#print(\"The Combined F1 scores of Terminals \",f1_state_terminal) # order available, passive, charging, offline, down\n",
        "for i in range(len(label_count)-1):\n",
        "    f1_state_terminal[i]/=273\n",
        "print(\"The Combined Average F1 scores of train Terminals \",f1_state_terminal) # order available, passive, charging, offline, down\n",
        "\n",
        "#print(\"The Combined F1 scores of test Terminals \",f1_state_terminal_test) # order available, passive, charging, offline, down\n",
        "for i in range(len(label_count)-1):\n",
        "    f1_state_terminal_test[i]/=273\n",
        "print(\"The Combined Average F1 scores of test Terminals \",f1_state_terminal_test) # order available, passive, charging, offline,down\n",
        "\n",
        "f1_final=0\n",
        "#print(\" The probabilities of the train states\",prob_list)\n",
        "for i in range(len(prob_list)):\n",
        "    f1_final+=prob_list[i]*f1_state_terminal[i]\n",
        "print('The final F1 score is', f1_final)\n",
        "\n",
        "f1_final_test=0\n",
        "\n",
        "for i in range(len(prob_list)):\n",
        "    f1_final_test+=prob_list[i]*f1_state_terminal_test[i]\n",
        "print('The final F1 score is', f1_final_test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Combined Average F1 scores of train Terminals  [0.6086979810328907, 0.30881155417912987, 0.42195637968342575, 0.5934121586492463, 0.3539468882364999, 0]\n",
            "The Combined Average F1 scores of test Terminals  [0.3704549261435706, 0.1173166136347936, 0.0892834791177464, 0.10503660221001507, 0.13422039056801288, 0]\n",
            "The final F1 score is 0.5511260645525401\n",
            "The final F1 score is 0.26601179994017726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw9QskvylyA2"
      },
      "source": [
        "LSTM based model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgqgQF9Z8usi"
      },
      "source": [
        "X_tr1 = array(X_tr).reshape(X_tr.shape[0],1, X_tr.shape[1])\n",
        "X_te1 = array(X_te).reshape(X_te.shape[0], 1,X_te.shape[1])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMv_HHoA84gG",
        "outputId": "f1f4086d-ab30-418d-8459-38de8d833cc6"
      },
      "source": [
        "\n",
        "f1_state_terminal=[0,0,0,0,0, 0] # order available, passive, charging, offline, down\n",
        "f1_state_terminal_test=[0,0,0,0,0, 0] # order available, passive, charging, offline, down\n",
        "label_count=[0,0,0,0,0,0]\n",
        "\n",
        "for i in tqdm(range(0,data.shape[1])):\n",
        "  tf.keras.backend.clear_session()\n",
        "  \n",
        "  terminal= data.columns[i] # Extracting the column names from the dataframe\n",
        "    #num_class=data[terminal].unique() # Unique labels present in the dataframe column\n",
        "  weekend=data[terminal].apply(label_encoder)\n",
        "  num_class=weekend.unique()\n",
        "  num_class.sort()\n",
        "  weekend_test=test_data[terminal].apply(label_encoder)\n",
        "  num_class_test=weekend_test.unique()\n",
        "  num_class_test.sort()\n",
        "  if len(num_class)>1:\n",
        "    unit=len(num_class)\n",
        "    #print(unit)\n",
        "    y=np.array(weekend).reshape(-1,1) # label encoding class labels\n",
        "    y_test=np.array(weekend_test).reshape(-1,1)\n",
        "    y_train1 = to_categorical(y, 5)\n",
        "    y_test1 = to_categorical(y_test, 5)\n",
        "    #print(y_train1.shape)\n",
        "    #print(y_test1.shape)   \n",
        "            # define model\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(128, activation='relu', input_shape=( 1, 18)))\n",
        "\n",
        "    model.add(Dense(200, activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(50))\n",
        "    model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "    model.fit(X_tr1, y_train1, epochs=15, batch_size=50, verbose=0)\n",
        "    \n",
        "    #class_weights = class_weight.compute_class_weight('balanced',weekend.unique(y) ,data[terminal])\n",
        "    #class_weights = dict(enumerate(class_weights))\n",
        "    #model.fit(X_tr, y_train1, epochs=10, batch_size=100, validation_data=(X_te,y_test1), verbose=0)\n",
        "        \n",
        "    y_pred=model.predict(X_tr1)\n",
        "    val_predict=np.argmax(y_pred, axis=1) \n",
        "    val_target=np.argmax(y_train1, axis=1) \n",
        "    state_f1=f1_score(val_target, val_predict, average=None)\n",
        "        \n",
        "    y_pred_test=model.predict(X_te1)\n",
        "    val_predict=np.argmax(y_pred_test, axis=1) \n",
        "    val_target=np.argmax(y_test1, axis=1) \n",
        "    state_f1_test=f1_score(val_target, val_predict, average=None)\n",
        "        \n",
        "    idx=0\n",
        "    for label in num_class:\n",
        "            #print(\"more than 1\",num_class)\n",
        "        f1_state_terminal[label]+=state_f1[idx]\n",
        "        label_count[label]+=1\n",
        "        idx+=1\n",
        "            #print('passed from if ')\n",
        "            \n",
        "    idx=0\n",
        "    for label in num_class_test:\n",
        "        f1_state_terminal_test[label]+=state_f1_test[idx]\n",
        "        idx+=1\n",
        "          \n",
        "  else:\n",
        "    for label in num_class:\n",
        "            #print('1 class',num_class)\n",
        "        f1_state_terminal[label]+=1 # Adding F1 score as 1 to the state where a terminal is in only one mode\n",
        "        label_count[label]+=1\n",
        "            #print('passed from else')\n",
        "        \n",
        "    for label in num_class_test:\n",
        "        f1_state_terminal_test[label]+=1 # Adding F1 score as 1 to the state where a terminal is in only one mode\n",
        "    "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/273 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  1%|          | 2/273 [00:51<1:55:56, 25.67s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  1%|▏         | 4/273 [01:32<1:48:26, 24.19s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  2%|▏         | 6/273 [02:14<1:43:20, 23.22s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  3%|▎         | 7/273 [02:57<2:08:18, 28.94s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  3%|▎         | 8/273 [03:39<2:26:13, 33.11s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  4%|▍         | 11/273 [04:21<1:59:18, 27.32s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  4%|▍         | 12/273 [05:02<2:16:50, 31.46s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  5%|▍         | 13/273 [05:44<2:29:51, 34.58s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  5%|▌         | 14/273 [06:27<2:39:59, 37.06s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  5%|▌         | 15/273 [07:07<2:44:03, 38.15s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  6%|▌         | 16/273 [07:50<2:49:07, 39.48s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  6%|▌         | 17/273 [08:32<2:52:15, 40.37s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  7%|▋         | 18/273 [09:15<2:54:17, 41.01s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  7%|▋         | 19/273 [09:57<2:54:34, 41.24s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  7%|▋         | 20/273 [10:37<2:53:18, 41.10s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  8%|▊         | 21/273 [11:19<2:53:27, 41.30s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  8%|▊         | 22/273 [12:02<2:54:05, 41.61s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  8%|▊         | 23/273 [12:43<2:52:40, 41.44s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  9%|▉         | 24/273 [13:24<2:52:02, 41.46s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  9%|▉         | 25/273 [14:07<2:52:51, 41.82s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 10%|▉         | 26/273 [14:49<2:52:46, 41.97s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 10%|▉         | 27/273 [15:32<2:52:39, 42.11s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 10%|█         | 28/273 [16:14<2:52:43, 42.30s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 11%|█         | 29/273 [16:56<2:51:32, 42.18s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 11%|█         | 30/273 [17:38<2:49:49, 41.93s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 11%|█▏        | 31/273 [18:19<2:48:05, 41.67s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 12%|█▏        | 32/273 [19:02<2:49:10, 42.12s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 12%|█▏        | 33/273 [19:44<2:48:13, 42.06s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 12%|█▏        | 34/273 [20:25<2:46:23, 41.77s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 14%|█▎        | 37/273 [21:06<2:11:15, 33.37s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 14%|█▍        | 38/273 [21:48<2:20:32, 35.88s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 14%|█▍        | 39/273 [22:30<2:27:14, 37.76s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 15%|█▍        | 40/273 [23:11<2:30:51, 38.85s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 15%|█▌        | 41/273 [23:54<2:34:26, 39.94s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 15%|█▌        | 42/273 [24:37<2:37:15, 40.85s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 16%|█▌        | 43/273 [25:18<2:37:10, 41.00s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 16%|█▌        | 44/273 [26:01<2:38:02, 41.41s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 16%|█▋        | 45/273 [26:43<2:38:38, 41.75s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 17%|█▋        | 46/273 [27:24<2:36:56, 41.48s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 17%|█▋        | 47/273 [28:06<2:36:46, 41.62s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 18%|█▊        | 48/273 [28:48<2:36:51, 41.83s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 18%|█▊        | 49/273 [29:30<2:36:40, 41.97s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 18%|█▊        | 50/273 [30:13<2:36:08, 42.01s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 19%|█▊        | 51/273 [30:54<2:34:55, 41.87s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 19%|█▉        | 52/273 [31:36<2:33:43, 41.74s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 19%|█▉        | 53/273 [32:18<2:33:44, 41.93s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 21%|██        | 56/273 [32:59<2:01:08, 33.49s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 21%|██        | 57/273 [33:40<2:08:47, 35.77s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 21%|██        | 58/273 [34:24<2:16:06, 37.98s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 22%|██▏       | 59/273 [35:06<2:20:01, 39.26s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 22%|██▏       | 60/273 [35:48<2:22:28, 40.13s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 22%|██▏       | 61/273 [36:29<2:22:55, 40.45s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 23%|██▎       | 62/273 [37:11<2:24:01, 40.95s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 23%|██▎       | 63/273 [37:54<2:24:53, 41.40s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 23%|██▎       | 64/273 [38:35<2:23:53, 41.31s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 24%|██▍       | 65/273 [39:15<2:22:22, 41.07s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 24%|██▍       | 66/273 [39:59<2:23:57, 41.73s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 25%|██▍       | 67/273 [40:40<2:22:26, 41.49s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 25%|██▍       | 68/273 [41:22<2:22:31, 41.71s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 25%|██▌       | 69/273 [42:03<2:21:13, 41.54s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 26%|██▌       | 70/273 [42:45<2:21:24, 41.80s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 26%|██▌       | 71/273 [43:26<2:20:03, 41.60s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 26%|██▋       | 72/273 [44:08<2:19:02, 41.51s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 27%|██▋       | 73/273 [44:51<2:20:11, 42.06s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 27%|██▋       | 74/273 [45:34<2:20:14, 42.28s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 27%|██▋       | 75/273 [46:16<2:19:15, 42.20s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 28%|██▊       | 76/273 [46:58<2:18:49, 42.28s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 28%|██▊       | 77/273 [47:41<2:18:43, 42.46s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 29%|██▊       | 78/273 [48:24<2:18:24, 42.59s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 29%|██▉       | 79/273 [49:06<2:16:59, 42.37s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 29%|██▉       | 80/273 [49:48<2:16:12, 42.34s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 30%|██▉       | 81/273 [50:32<2:16:33, 42.68s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 30%|███       | 82/273 [51:13<2:14:49, 42.36s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 30%|███       | 83/273 [51:55<2:13:49, 42.26s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 31%|███       | 84/273 [52:38<2:13:33, 42.40s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 31%|███       | 85/273 [53:19<2:10:57, 41.79s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 32%|███▏      | 86/273 [54:00<2:10:22, 41.83s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 32%|███▏      | 87/273 [54:43<2:10:09, 41.98s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 32%|███▏      | 88/273 [55:25<2:09:38, 42.05s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 33%|███▎      | 89/273 [56:07<2:09:10, 42.12s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 33%|███▎      | 91/273 [56:50<1:48:41, 35.83s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 34%|███▎      | 92/273 [57:32<1:54:23, 37.92s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 34%|███▍      | 93/273 [58:15<1:57:43, 39.24s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 34%|███▍      | 94/273 [58:56<1:59:06, 39.92s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 35%|███▍      | 95/273 [59:38<1:59:46, 40.37s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 35%|███▌      | 96/273 [1:00:21<2:01:50, 41.30s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 36%|███▌      | 97/273 [1:01:03<2:01:56, 41.57s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 36%|███▌      | 98/273 [1:01:46<2:01:57, 41.81s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 36%|███▋      | 99/273 [1:02:28<2:01:52, 42.03s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 37%|███▋      | 100/273 [1:03:12<2:02:30, 42.49s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 37%|███▋      | 102/273 [1:03:54<1:42:40, 36.02s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 38%|███▊      | 103/273 [1:04:35<1:46:43, 37.67s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 38%|███▊      | 104/273 [1:05:17<1:49:57, 39.04s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 38%|███▊      | 105/273 [1:06:00<1:52:07, 40.04s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 39%|███▉      | 107/273 [1:06:42<1:34:56, 34.32s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 40%|███▉      | 108/273 [1:07:23<1:39:55, 36.34s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 40%|███▉      | 109/273 [1:08:05<1:44:06, 38.09s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 40%|████      | 110/273 [1:08:48<1:47:18, 39.50s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 41%|████      | 111/273 [1:09:30<1:48:52, 40.32s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 41%|████      | 112/273 [1:10:10<1:48:20, 40.38s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 41%|████▏     | 113/273 [1:10:52<1:48:39, 40.74s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 42%|████▏     | 114/273 [1:11:35<1:50:02, 41.53s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 42%|████▏     | 115/273 [1:12:19<1:50:48, 42.08s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 42%|████▏     | 116/273 [1:12:59<1:48:48, 41.59s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 43%|████▎     | 117/273 [1:13:40<1:47:35, 41.38s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 43%|████▎     | 118/273 [1:14:22<1:47:01, 41.43s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 44%|████▎     | 119/273 [1:15:03<1:46:40, 41.56s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 44%|████▍     | 120/273 [1:15:45<1:46:04, 41.60s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 44%|████▍     | 121/273 [1:16:27<1:45:15, 41.55s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 45%|████▍     | 122/273 [1:17:08<1:44:30, 41.52s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 45%|████▌     | 123/273 [1:17:50<1:44:00, 41.60s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 45%|████▌     | 124/273 [1:18:32<1:43:36, 41.72s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 46%|████▌     | 125/273 [1:19:14<1:43:06, 41.80s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 46%|████▌     | 126/273 [1:19:57<1:43:24, 42.21s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 47%|████▋     | 127/273 [1:20:39<1:42:38, 42.18s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 47%|████▋     | 128/273 [1:21:22<1:42:22, 42.36s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 47%|████▋     | 129/273 [1:22:03<1:40:59, 42.08s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 48%|████▊     | 130/273 [1:22:44<1:39:26, 41.73s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 49%|████▉     | 134/273 [1:23:26<1:15:00, 32.37s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 49%|████▉     | 135/273 [1:24:07<1:20:08, 34.85s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 50%|████▉     | 136/273 [1:24:48<1:23:55, 36.75s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 50%|█████     | 137/273 [1:25:30<1:26:59, 38.38s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 51%|█████     | 138/273 [1:26:13<1:29:16, 39.68s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 51%|█████     | 139/273 [1:26:55<1:29:50, 40.23s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 51%|█████▏    | 140/273 [1:27:35<1:29:14, 40.26s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 52%|█████▏    | 141/273 [1:28:17<1:29:24, 40.64s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 52%|█████▏    | 142/273 [1:28:59<1:30:06, 41.27s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 52%|█████▏    | 143/273 [1:29:42<1:30:14, 41.65s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 53%|█████▎    | 144/273 [1:30:24<1:29:35, 41.67s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 145/273 [1:31:05<1:28:58, 41.71s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 53%|█████▎    | 146/273 [1:31:48<1:28:36, 41.86s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 54%|█████▍    | 147/273 [1:32:29<1:27:38, 41.73s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 54%|█████▍    | 148/273 [1:33:09<1:26:08, 41.35s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 55%|█████▍    | 149/273 [1:33:52<1:26:18, 41.77s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 55%|█████▍    | 150/273 [1:34:34<1:25:25, 41.67s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 55%|█████▌    | 151/273 [1:35:15<1:24:48, 41.71s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 56%|█████▌    | 152/273 [1:35:58<1:24:32, 41.92s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 56%|█████▌    | 153/273 [1:36:42<1:24:56, 42.47s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 56%|█████▋    | 154/273 [1:37:24<1:24:09, 42.43s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 57%|█████▋    | 155/273 [1:38:05<1:22:45, 42.08s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 57%|█████▋    | 156/273 [1:38:47<1:21:46, 41.93s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 58%|█████▊    | 158/273 [1:39:29<1:08:16, 35.63s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 58%|█████▊    | 159/273 [1:40:10<1:11:03, 37.40s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 59%|█████▊    | 160/273 [1:40:51<1:12:31, 38.51s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 59%|█████▉    | 161/273 [1:41:33<1:13:50, 39.55s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 59%|█████▉    | 162/273 [1:42:15<1:14:18, 40.17s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 60%|█████▉    | 163/273 [1:42:56<1:14:22, 40.57s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 60%|██████    | 164/273 [1:43:39<1:14:38, 41.08s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 60%|██████    | 165/273 [1:44:21<1:14:49, 41.57s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 61%|██████    | 166/273 [1:45:03<1:14:26, 41.74s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 61%|██████    | 167/273 [1:45:46<1:14:03, 41.92s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 62%|██████▏   | 168/273 [1:46:28<1:13:38, 42.08s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 62%|██████▏   | 169/273 [1:47:11<1:13:13, 42.25s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 62%|██████▏   | 170/273 [1:47:53<1:12:22, 42.16s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 63%|██████▎   | 171/273 [1:48:34<1:10:57, 41.74s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 63%|██████▎   | 172/273 [1:49:17<1:10:57, 42.15s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 63%|██████▎   | 173/273 [1:49:57<1:09:30, 41.70s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 64%|██████▍   | 175/273 [1:50:39<57:48, 35.40s/it]  \u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 65%|██████▍   | 177/273 [1:51:21<49:53, 31.19s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 65%|██████▌   | 178/273 [1:52:02<54:02, 34.13s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 66%|██████▌   | 179/273 [1:52:44<56:46, 36.24s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 66%|██████▋   | 181/273 [1:53:25<48:21, 31.54s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 67%|██████▋   | 182/273 [1:54:08<53:04, 34.99s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 67%|██████▋   | 183/273 [1:54:50<55:42, 37.14s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 67%|██████▋   | 184/273 [1:55:31<56:51, 38.34s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 68%|██████▊   | 185/273 [1:56:13<57:45, 39.38s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 68%|██████▊   | 186/273 [1:56:55<58:22, 40.26s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 68%|██████▊   | 187/273 [1:57:36<57:54, 40.40s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 69%|██████▉   | 188/273 [1:58:18<57:58, 40.92s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 69%|██████▉   | 189/273 [1:59:00<57:47, 41.28s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 70%|██████▉   | 190/273 [1:59:43<57:40, 41.69s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 70%|██████▉   | 191/273 [2:00:24<56:56, 41.66s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 70%|███████   | 192/273 [2:01:05<55:53, 41.41s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 71%|███████▏  | 195/273 [2:01:48<43:11, 33.22s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 72%|███████▏  | 196/273 [2:02:30<46:11, 35.99s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 72%|███████▏  | 197/273 [2:03:11<47:36, 37.58s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 73%|███████▎  | 198/273 [2:03:54<48:43, 38.98s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 73%|███████▎  | 199/273 [2:04:35<49:02, 39.76s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 73%|███████▎  | 200/273 [2:05:16<48:36, 39.95s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 74%|███████▎  | 201/273 [2:05:57<48:37, 40.52s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 74%|███████▍  | 202/273 [2:06:39<48:24, 40.91s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 74%|███████▍  | 203/273 [2:07:23<48:42, 41.76s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 75%|███████▍  | 204/273 [2:08:05<48:11, 41.90s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 75%|███████▌  | 205/273 [2:08:48<47:41, 42.08s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 75%|███████▌  | 206/273 [2:09:29<46:47, 41.91s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 76%|███████▌  | 207/273 [2:10:11<46:05, 41.90s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 76%|███████▌  | 208/273 [2:10:52<45:04, 41.61s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 77%|███████▋  | 209/273 [2:11:34<44:23, 41.61s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 77%|███████▋  | 210/273 [2:12:16<43:46, 41.70s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 77%|███████▋  | 211/273 [2:12:58<43:13, 41.83s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 78%|███████▊  | 212/273 [2:13:38<42:03, 41.37s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 78%|███████▊  | 213/273 [2:14:19<41:14, 41.24s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 79%|███████▉  | 215/273 [2:15:02<34:05, 35.26s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 79%|███████▉  | 216/273 [2:15:43<35:21, 37.22s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 79%|███████▉  | 217/273 [2:16:24<35:45, 38.31s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 80%|███████▉  | 218/273 [2:17:05<35:54, 39.18s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 81%|████████  | 220/273 [2:17:49<29:56, 33.90s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 81%|████████  | 221/273 [2:18:31<31:35, 36.46s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 81%|████████▏ | 222/273 [2:19:13<32:26, 38.17s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 82%|████████▏ | 223/273 [2:19:56<32:52, 39.44s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 82%|████████▏ | 224/273 [2:20:38<32:56, 40.33s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 82%|████████▏ | 225/273 [2:21:19<32:28, 40.59s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 83%|████████▎ | 226/273 [2:22:02<32:15, 41.18s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 83%|████████▎ | 227/273 [2:22:44<31:51, 41.55s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 84%|████████▍ | 229/273 [2:23:26<25:56, 35.37s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 84%|████████▍ | 230/273 [2:24:08<26:41, 37.25s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 85%|████████▍ | 231/273 [2:24:49<26:59, 38.55s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 85%|████████▍ | 232/273 [2:25:31<27:01, 39.56s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 85%|████████▌ | 233/273 [2:26:13<26:46, 40.15s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 86%|████████▌ | 234/273 [2:26:55<26:28, 40.72s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 86%|████████▌ | 235/273 [2:27:37<26:00, 41.07s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 86%|████████▋ | 236/273 [2:28:19<25:35, 41.51s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 87%|████████▋ | 237/273 [2:29:02<25:04, 41.80s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 87%|████████▋ | 238/273 [2:29:45<24:42, 42.35s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 88%|████████▊ | 239/273 [2:30:27<23:50, 42.09s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 88%|████████▊ | 240/273 [2:31:09<23:05, 41.98s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 88%|████████▊ | 241/273 [2:31:50<22:18, 41.83s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 89%|████████▊ | 242/273 [2:32:32<21:41, 41.98s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 89%|████████▉ | 243/273 [2:33:15<21:01, 42.04s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 89%|████████▉ | 244/273 [2:33:58<20:28, 42.38s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 90%|█████████ | 247/273 [2:34:39<14:38, 33.77s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 91%|█████████ | 248/273 [2:35:21<15:11, 36.45s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 91%|█████████ | 249/273 [2:36:03<15:08, 37.87s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 92%|█████████▏| 250/273 [2:36:45<15:00, 39.16s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 92%|█████████▏| 252/273 [2:37:25<11:42, 33.47s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 93%|█████████▎| 253/273 [2:38:07<12:00, 36.01s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 93%|█████████▎| 254/273 [2:38:49<11:56, 37.70s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 93%|█████████▎| 255/273 [2:39:31<11:44, 39.16s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 94%|█████████▍| 256/273 [2:40:13<11:20, 40.03s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 94%|█████████▍| 257/273 [2:40:56<10:52, 40.80s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 95%|█████████▍| 259/273 [2:41:38<08:07, 34.85s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 95%|█████████▌| 260/273 [2:42:20<08:00, 37.00s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 96%|█████████▌| 261/273 [2:43:01<07:39, 38.28s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 96%|█████████▌| 262/273 [2:43:45<07:18, 39.86s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 96%|█████████▋| 263/273 [2:44:29<06:50, 41.03s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 97%|█████████▋| 265/273 [2:45:11<04:40, 35.10s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 97%|█████████▋| 266/273 [2:45:54<04:21, 37.31s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 98%|█████████▊| 267/273 [2:46:36<03:54, 39.00s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 98%|█████████▊| 268/273 [2:47:19<03:20, 40.19s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 99%|█████████▊| 269/273 [2:48:01<02:42, 40.72s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 99%|█████████▉| 270/273 [2:48:46<02:05, 41.93s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " 99%|█████████▉| 271/273 [2:49:29<01:24, 42.27s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "100%|█████████▉| 272/273 [2:50:11<00:42, 42.09s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "100%|██████████| 273/273 [2:50:54<00:00, 37.56s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEgsRSHxk2dj",
        "outputId": "fc3d93f6-5d5b-4f38-ba38-f2510256d9b3"
      },
      "source": [
        "#print('The counts of the class labels in train data', label_count)\n",
        "#print(\"The Combined F1 scores of Terminals \",f1_state_terminal) # order available, passive, charging, offline, down\n",
        "for i in range(len(label_count)-1):\n",
        "    f1_state_terminal[i]/=273\n",
        "print(\"The Combined Average F1 scores of train Terminals \",f1_state_terminal) # order available, passive, charging, offline, down\n",
        "\n",
        "#print(\"The Combined F1 scores of test Terminals \",f1_state_terminal_test) # order available, passive, charging, offline, down\n",
        "for i in range(len(label_count)-1):\n",
        "    f1_state_terminal_test[i]/=273\n",
        "print(\"The Combined Average F1 scores of test Terminals \",f1_state_terminal_test) # order available, passive, charging, offline,down\n",
        "\n",
        "f1_final=0\n",
        "#print(\" The probabilities of the train states\",prob_list)\n",
        "for i in range(len(prob_list)):\n",
        "    f1_final+=prob_list[i]*f1_state_terminal[i]\n",
        "print('The final F1 score is', f1_final)\n",
        "\n",
        "f1_final_test=0\n",
        "\n",
        "for i in range(len(prob_list)):\n",
        "    f1_final_test+=prob_list[i]*f1_state_terminal_test[i]\n",
        "print('The final F1 score is', f1_final_test)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Combined Average F1 scores of train Terminals  [0.8720513882949165, 0.31633619886168374, 0.5925047964240113, 0.7257569571129644, 0.3873240599111841, 0]\n",
            "The Combined Average F1 scores of test Terminals  [0.5774743703325854, 0.04662304343503901, 0.05760982685344029, 0.09004004658722199, 0.1367597166364328, 0]\n",
            "The final F1 score is 0.7461846980316141\n",
            "The final F1 score is 0.380231904805819\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}